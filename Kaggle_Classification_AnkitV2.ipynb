{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fec24a3993df438ba67906e531bb7832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67390c0f0191498cb472effe45608186",
              "IPY_MODEL_5eae86f0e22f4e23a1f722e5940760cc",
              "IPY_MODEL_a2158c50708244ba8fb14b8b872572bc"
            ],
            "layout": "IPY_MODEL_b1c68c550bfa47b2846b4b1e9e796b3e"
          }
        },
        "67390c0f0191498cb472effe45608186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3d25e708d840ae9a5381dd0390b61b",
            "placeholder": "​",
            "style": "IPY_MODEL_69525a34deb94341a1afa50ee939716a",
            "value": "Optimization Progress: "
          }
        },
        "5eae86f0e22f4e23a1f722e5940760cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1008adabde8d4e0ba6816c5194f681b4",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d928ab6d124c1b98988fce8d4d3bce",
            "value": 300
          }
        },
        "a2158c50708244ba8fb14b8b872572bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39379970d2fa45748443cd01e1bb38e4",
            "placeholder": "​",
            "style": "IPY_MODEL_adc0ea92bd1644dd8ee317b86a28c0df",
            "value": " 310/? [3:27:24&lt;00:00, 26.70s/pipeline]"
          }
        },
        "b1c68c550bfa47b2846b4b1e9e796b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5b3d25e708d840ae9a5381dd0390b61b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69525a34deb94341a1afa50ee939716a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1008adabde8d4e0ba6816c5194f681b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d928ab6d124c1b98988fce8d4d3bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39379970d2fa45748443cd01e1bb38e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc0ea92bd1644dd8ee317b86a28c0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianMutisyo/Lets-Go-Sixers/blob/main/Kaggle_Classification_AnkitV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD8BqnKbxX3_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello world!"
      ],
      "metadata": {
        "id": "-t4bq3quxv-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sam's Section"
      ],
      "metadata": {
        "id": "fPdOEDKJx6mD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ankit's Section"
      ],
      "metadata": {
        "id": "Axj7dWVkyNxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the training and test data"
      ],
      "metadata": {
        "id": "7opfNNvyFmzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')"
      ],
      "metadata": {
        "id": "-REb6ZnZ3xkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove output column in training data and assign it as the label to predict"
      ],
      "metadata": {
        "id": "1SJ9NJR5FvvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']"
      ],
      "metadata": {
        "id": "HDqwNVOV4JBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical columns to be encoded\n",
        "categorical_columns = ['subject', 'phase', 'state']"
      ],
      "metadata": {
        "id": "uSOhBGdO4Nid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for categorical columns\n",
        "onehot_encoder = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
        "], remainder='passthrough')"
      ],
      "metadata": {
        "id": "1RFpeF5K4SW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the train and test data\n",
        "X_encoded = onehot_encoder.fit_transform(X)\n",
        "test_data_encoded = onehot_encoder.transform(test_data)"
      ],
      "metadata": {
        "id": "12FWe-VM4WYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vRFBsM9e4XvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a random forest classifier"
      ],
      "metadata": {
        "id": "8nReVJekF-rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "wKqeu93K4aw5",
        "outputId": "b16b7f12-2769-4bbd-96ed-b51533d3f39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "y_val_pred = rf_model.predict(X_val)\n",
        "validation_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {validation_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIdh-Kk04hXg",
        "outputId": "cb811a50-7e3b-43a5-bac4-5f22ce52e1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "test_predictions = rf_model.predict(test_data_encoded)"
      ],
      "metadata": {
        "id": "jweuV8Lz4odo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})"
      ],
      "metadata": {
        "id": "O4IDbUEu4rIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the predictions to a CSV file\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "IU8qMc1K4t9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVEFboIY4wrX",
        "outputId": "eefbc925-5de3-4b07-a4f2-b688a6c8e9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This results in test accuracy in Kaggle of 54%"
      ],
      "metadata": {
        "id": "Ms0gNvraGL5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying below Enhancements\n",
        "* Scaling: The numeric columns are scaled using StandardScaler to help the model handle numeric values more efficiently.\n",
        "* Hyperparameter Tuning: GridSearchCV is used to find the best combination of Random Forest hyperparameters.\n",
        "* Cross-Validation: Instead of using a single validation split, k-fold cross-validation (with cv=5) gives a more robust score."
      ],
      "metadata": {
        "id": "8RbIHstP5yWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Preprocessing: One-hot encoding for categorical columns, scaling for numeric columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Define XGBoost model with GPU support\n",
        "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist', use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Define a pipeline: preprocessing followed by XGBoost\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', xgb_model)\n",
        "])\n",
        "\n",
        "# Randomized Search Parameters\n",
        "param_distributions = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [3, 6, 9],\n",
        "    'classifier__learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV with parallelization and GPU-accelerated XGBoost\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline, param_distributions, n_iter=10, scoring='accuracy', cv=5, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X, y)\n",
        "\n",
        "# Best parameters and score\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "print(f\"Best Cross-validation Score: {random_search.best_score_:.4f}\")\n",
        "\n",
        "# Predict on the test data\n",
        "test_data_encoded = random_search.best_estimator_.named_steps['preprocessor'].transform(test_data)\n",
        "test_predictions = random_search.best_estimator_.named_steps['classifier'].predict(test_data_encoded)\n",
        "\n",
        "# Format the predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission_df.to_csv('submission_gpu.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_gpu.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDc7aFTf8Zyj",
        "outputId": "e141e3a5-53b9-4d84-a682-bf4753b7aea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:04:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:04:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'classifier__n_estimators': 200, 'classifier__max_depth': 9, 'classifier__learning_rate': 0.1}\n",
            "Best Cross-validation Score: 0.8656\n",
            "Predictions saved to submission_gpu.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:04:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:04:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3s8p0ah97xv",
        "outputId": "917df52c-93b9-4214-e91a-5d2af236178f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Preprocessing: One-hot encoding for categorical columns, scaling for numeric columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_valid = preprocessor.transform(X_valid)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'tree_method': 'hist',  # Faster on GPU\n",
        "        'device': 'cuda',  # GPU support\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
        "    }\n",
        "\n",
        "    # Train XGBoost model\n",
        "    model = xgb.XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Validate the model\n",
        "    score = model.score(X_valid, y_valid)\n",
        "    return score\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "\n",
        "# Train on full data using best hyperparameters\n",
        "best_model = xgb.XGBClassifier(**study.best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "test_data_encoded = preprocessor.transform(test_data)\n",
        "test_predictions = best_model.predict(test_data_encoded)\n",
        "\n",
        "# Format the predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission_df.to_csv('submission_optuna.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_optuna.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QubAo70_9_Fr",
        "outputId": "79e30902-53ba-4bef-d957-679b4159233f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-19 18:09:19,371] A new study created in memory with name: no-name-0cd94eea-f786-44ac-b931-ca998f26d2ef\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:26,699] Trial 0 finished with value: 0.8538713195201745 and parameters: {'n_estimators': 545, 'max_depth': 10, 'learning_rate': 0.05999025028123221, 'subsample': 0.6527704946107059, 'colsample_bytree': 0.5053480249649472, 'lambda': 0.03958551551372708, 'alpha': 0.7714255394145872}. Best is trial 0 with value: 0.8538713195201745.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:34,647] Trial 1 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 271, 'max_depth': 15, 'learning_rate': 0.023625552345569702, 'subsample': 0.8253577293301073, 'colsample_bytree': 0.7528267475965027, 'lambda': 0.017803919394525206, 'alpha': 0.38091483831562334}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:38,233] Trial 2 finished with value: 0.8516902944383861 and parameters: {'n_estimators': 367, 'max_depth': 8, 'learning_rate': 0.043696190401666946, 'subsample': 0.6060276124887045, 'colsample_bytree': 0.5590411835449808, 'lambda': 0.24211057685675863, 'alpha': 9.126224807533422}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:43,871] Trial 3 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 320, 'max_depth': 13, 'learning_rate': 0.03787029086245789, 'subsample': 0.5053595955106628, 'colsample_bytree': 0.6836973069170689, 'lambda': 0.004160923446862892, 'alpha': 0.006949410863310833}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:46,310] Trial 4 finished with value: 0.8527808069792803 and parameters: {'n_estimators': 196, 'max_depth': 14, 'learning_rate': 0.29453795005463573, 'subsample': 0.5744839996547314, 'colsample_bytree': 0.5647481872575858, 'lambda': 5.41221975579931, 'alpha': 0.46309773330881115}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:50,285] Trial 5 finished with value: 0.8527808069792803 and parameters: {'n_estimators': 145, 'max_depth': 14, 'learning_rate': 0.07718071477487272, 'subsample': 0.7385235187143985, 'colsample_bytree': 0.9031643792428532, 'lambda': 5.182193567357808, 'alpha': 0.010192830923533217}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:09:54,082] Trial 6 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 524, 'max_depth': 11, 'learning_rate': 0.2500670842957004, 'subsample': 0.9070574572974242, 'colsample_bytree': 0.6509900185942474, 'lambda': 0.2503987379332224, 'alpha': 0.029004050749728675}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:00,801] Trial 7 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 670, 'max_depth': 8, 'learning_rate': 0.08225714848924193, 'subsample': 0.8512591690370135, 'colsample_bytree': 0.8423739729328068, 'lambda': 0.025107908003056005, 'alpha': 1.0246583135211853}. Best is trial 1 with value: 0.8636859323882224.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:03,421] Trial 8 finished with value: 0.871319520174482 and parameters: {'n_estimators': 148, 'max_depth': 9, 'learning_rate': 0.02646951866292583, 'subsample': 0.9787557606470543, 'colsample_bytree': 0.6081100130296041, 'lambda': 0.036991321518017616, 'alpha': 0.03790561304646741}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:06,956] Trial 9 finished with value: 0.8604143947655398 and parameters: {'n_estimators': 835, 'max_depth': 4, 'learning_rate': 0.012367854128513659, 'subsample': 0.9450271991898813, 'colsample_bytree': 0.8807529579090231, 'lambda': 0.03484334741053398, 'alpha': 0.00112874977780339}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:12,533] Trial 10 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 988, 'max_depth': 5, 'learning_rate': 0.010455558506919403, 'subsample': 0.9808607396995686, 'colsample_bytree': 0.7708559736389529, 'lambda': 0.0028786860637336938, 'alpha': 0.08374425284289574}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:13,647] Trial 11 finished with value: 0.8658669574700109 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.021664816981472518, 'subsample': 0.8131497613132908, 'colsample_bytree': 0.7514422578036756, 'lambda': 0.009250343868409557, 'alpha': 0.16860086183381406}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:14,971] Trial 12 finished with value: 0.8604143947655398 and parameters: {'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.01726253131859432, 'subsample': 0.7484576106731721, 'colsample_bytree': 0.9723664436547788, 'lambda': 0.0010205315586162974, 'alpha': 0.09129732280375309}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:19,554] Trial 13 finished with value: 0.8593238822246456 and parameters: {'n_estimators': 445, 'max_depth': 7, 'learning_rate': 0.028024064921806875, 'subsample': 0.8424330030749116, 'colsample_bytree': 0.6654251707958123, 'lambda': 0.1545754579953581, 'alpha': 0.022595359332771795}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:20,364] Trial 14 finished with value: 0.8516902944383861 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.019061866863759352, 'subsample': 0.9984712096696362, 'colsample_bytree': 0.7998094809698356, 'lambda': 0.007379040905915794, 'alpha': 0.003046477524875092}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:23,552] Trial 15 finished with value: 0.8560523446019629 and parameters: {'n_estimators': 216, 'max_depth': 11, 'learning_rate': 0.1220891870599754, 'subsample': 0.9081942351384866, 'colsample_bytree': 0.6931249934080682, 'lambda': 1.107082540089323, 'alpha': 4.076290783625302}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:29,359] Trial 16 finished with value: 0.8593238822246456 and parameters: {'n_estimators': 420, 'max_depth': 9, 'learning_rate': 0.030139455051300213, 'subsample': 0.7890246673978416, 'colsample_bytree': 0.6085205023643228, 'lambda': 0.008915539779885982, 'alpha': 0.1688055177128673}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:35,230] Trial 17 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 666, 'max_depth': 6, 'learning_rate': 0.015511172108764444, 'subsample': 0.6974155728319957, 'colsample_bytree': 0.7241428126294778, 'lambda': 0.0010061984885667277, 'alpha': 0.03530219099237105}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:40,547] Trial 18 finished with value: 0.8647764449291166 and parameters: {'n_estimators': 264, 'max_depth': 12, 'learning_rate': 0.041960863154338314, 'subsample': 0.8929732087611492, 'colsample_bytree': 0.6045066821279999, 'lambda': 0.06542185410730494, 'alpha': 0.18634155165880625}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:52,914] Trial 19 finished with value: 0.8604143947655398 and parameters: {'n_estimators': 639, 'max_depth': 9, 'learning_rate': 0.022068836313036588, 'subsample': 0.7950113978180364, 'colsample_bytree': 0.8028568982669746, 'lambda': 0.4025684796545764, 'alpha': 1.7372190533944107}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:54,851] Trial 20 finished with value: 0.8669574700109052 and parameters: {'n_estimators': 204, 'max_depth': 7, 'learning_rate': 0.1322854751771175, 'subsample': 0.9481542701260837, 'colsample_bytree': 0.5104008363530382, 'lambda': 0.841829461599336, 'alpha': 0.05891383911255341}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:56,794] Trial 21 finished with value: 0.8691384950926936 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.12147976777764208, 'subsample': 0.9534995721388245, 'colsample_bytree': 0.5270698882445574, 'lambda': 0.9314793403887623, 'alpha': 0.05052232036949774}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:10:59,457] Trial 22 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 211, 'max_depth': 8, 'learning_rate': 0.15028103850489638, 'subsample': 0.9398029910181082, 'colsample_bytree': 0.5006466890026444, 'lambda': 1.5207938896739346, 'alpha': 0.048027534939350386}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:01,909] Trial 23 finished with value: 0.8669574700109052 and parameters: {'n_estimators': 346, 'max_depth': 7, 'learning_rate': 0.17489276414750013, 'subsample': 0.9546748143357268, 'colsample_bytree': 0.5475196914402447, 'lambda': 0.7651097532001547, 'alpha': 0.00976285612439802}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:04,912] Trial 24 finished with value: 0.8604143947655398 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.10781110953434107, 'subsample': 0.8725957176859045, 'colsample_bytree': 0.6027134557220415, 'lambda': 2.5409151019114833, 'alpha': 0.017251579187465945}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:06,502] Trial 25 finished with value: 0.861504907306434 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.21210068096153395, 'subsample': 0.9929379946164958, 'colsample_bytree': 0.5345365647569893, 'lambda': 0.5679503983928723, 'alpha': 0.05467730976035912}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:09,788] Trial 26 finished with value: 0.8560523446019629 and parameters: {'n_estimators': 412, 'max_depth': 7, 'learning_rate': 0.08941384662644292, 'subsample': 0.9277060933910473, 'colsample_bytree': 0.6290189359131113, 'lambda': 0.07567719402900334, 'alpha': 0.0037154228060707166}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:16,649] Trial 27 finished with value: 0.8647764449291166 and parameters: {'n_estimators': 485, 'max_depth': 10, 'learning_rate': 0.0679300323783552, 'subsample': 0.9688450465391235, 'colsample_bytree': 0.5795869517501957, 'lambda': 2.69517800774793, 'alpha': 0.2999496701064286}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:17,774] Trial 28 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 175, 'max_depth': 5, 'learning_rate': 0.11756773427231441, 'subsample': 0.876435243392368, 'colsample_bytree': 0.5221844239973125, 'lambda': 0.1324959148960768, 'alpha': 0.01383293669215305}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:25,800] Trial 29 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 594, 'max_depth': 9, 'learning_rate': 0.054980935549617284, 'subsample': 0.9234853456262972, 'colsample_bytree': 0.5114969200183255, 'lambda': 8.182341715921117, 'alpha': 0.06731074356874843}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:28,426] Trial 30 finished with value: 0.8560523446019629 and parameters: {'n_estimators': 261, 'max_depth': 11, 'learning_rate': 0.1569790859648665, 'subsample': 0.6557709503208053, 'colsample_bytree': 0.5763384866905619, 'lambda': 0.34997834491842666, 'alpha': 0.004689130529398989}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:30,804] Trial 31 finished with value: 0.8647764449291166 and parameters: {'n_estimators': 341, 'max_depth': 7, 'learning_rate': 0.1812693356409098, 'subsample': 0.9651477298921979, 'colsample_bytree': 0.5440874207239156, 'lambda': 0.7219809075797113, 'alpha': 0.001842140312707281}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:33,402] Trial 32 finished with value: 0.8571428571428571 and parameters: {'n_estimators': 244, 'max_depth': 8, 'learning_rate': 0.14783772062958586, 'subsample': 0.9516346918676749, 'colsample_bytree': 0.5567668994459747, 'lambda': 1.1160990054430049, 'alpha': 0.009249519433282576}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:36,084] Trial 33 finished with value: 0.8593238822246456 and parameters: {'n_estimators': 348, 'max_depth': 7, 'learning_rate': 0.2069151654345425, 'subsample': 0.8742069813040689, 'colsample_bytree': 0.5317080646611066, 'lambda': 2.2334729624514207, 'alpha': 0.028168551400701253}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:39,269] Trial 34 finished with value: 0.8680479825517994 and parameters: {'n_estimators': 295, 'max_depth': 8, 'learning_rate': 0.10115936130603392, 'subsample': 0.9712128694592257, 'colsample_bytree': 0.5022433004535448, 'lambda': 0.7275356311295924, 'alpha': 0.013502678483553888}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:41,640] Trial 35 finished with value: 0.8702290076335878 and parameters: {'n_estimators': 155, 'max_depth': 10, 'learning_rate': 0.09187583570364909, 'subsample': 0.9966359189603281, 'colsample_bytree': 0.5130058729735466, 'lambda': 0.20380909678805295, 'alpha': 0.12067048891726705}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:45,051] Trial 36 finished with value: 0.8658669574700109 and parameters: {'n_estimators': 298, 'max_depth': 10, 'learning_rate': 0.09807634478867722, 'subsample': 0.9770182131730804, 'colsample_bytree': 0.5863235615398024, 'lambda': 0.055964824300716115, 'alpha': 0.13185843777031103}. Best is trial 8 with value: 0.871319520174482.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:48,497] Trial 37 finished with value: 0.8724100327153762 and parameters: {'n_estimators': 160, 'max_depth': 12, 'learning_rate': 0.06806890658910449, 'subsample': 0.9995021266803916, 'colsample_bytree': 0.6285817854072765, 'lambda': 0.11019480721665534, 'alpha': 0.005958951726100463}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:51,656] Trial 38 finished with value: 0.8495092693565977 and parameters: {'n_estimators': 143, 'max_depth': 13, 'learning_rate': 0.06584880132170039, 'subsample': 0.5542246842359551, 'colsample_bytree': 0.6444667895983244, 'lambda': 0.19192325391684792, 'alpha': 0.005911089633464273}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:11:55,977] Trial 39 finished with value: 0.8680479825517994 and parameters: {'n_estimators': 157, 'max_depth': 15, 'learning_rate': 0.05177408129161942, 'subsample': 0.9184550684593984, 'colsample_bytree': 0.6980854329414772, 'lambda': 0.020394679272462357, 'alpha': 0.37058696868539936}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:05,917] Trial 40 finished with value: 0.8669574700109052 and parameters: {'n_estimators': 764, 'max_depth': 12, 'learning_rate': 0.04857799826072582, 'subsample': 0.9972603823309, 'colsample_bytree': 0.6285209021417526, 'lambda': 0.10016527831399794, 'alpha': 0.6652260264285192}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:08,713] Trial 41 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 149, 'max_depth': 12, 'learning_rate': 0.07779886261191252, 'subsample': 0.9993451277490735, 'colsample_bytree': 0.5029406312733348, 'lambda': 0.32924847108336974, 'alpha': 0.016639755480675516}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:13,111] Trial 42 finished with value: 0.8724100327153762 and parameters: {'n_estimators': 243, 'max_depth': 11, 'learning_rate': 0.03519726192615479, 'subsample': 0.9710601016824779, 'colsample_bytree': 0.5723014496365945, 'lambda': 0.030300770127173367, 'alpha': 0.03905542393835238}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:18,603] Trial 43 finished with value: 0.8680479825517994 and parameters: {'n_estimators': 235, 'max_depth': 14, 'learning_rate': 0.034442040420763466, 'subsample': 0.9034988844799512, 'colsample_bytree': 0.5694406577077478, 'lambda': 0.02790297500982768, 'alpha': 0.040761421478365284}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:22,704] Trial 44 finished with value: 0.8680479825517994 and parameters: {'n_estimators': 147, 'max_depth': 13, 'learning_rate': 0.034642976849710204, 'subsample': 0.9341621362387428, 'colsample_bytree': 0.6137706621999548, 'lambda': 0.0449352980389766, 'alpha': 0.11165773579435792}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:25,045] Trial 45 finished with value: 0.8702290076335878 and parameters: {'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.026501091153270782, 'subsample': 0.96888226879787, 'colsample_bytree': 0.5889846164151076, 'lambda': 0.01568180814078852, 'alpha': 0.028063617898042466}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:28,473] Trial 46 finished with value: 0.8680479825517994 and parameters: {'n_estimators': 118, 'max_depth': 11, 'learning_rate': 0.026315050110500667, 'subsample': 0.9725459693466768, 'colsample_bytree': 0.669060877163134, 'lambda': 0.015707155438732596, 'alpha': 0.02083847083696382}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:30,877] Trial 47 finished with value: 0.861504907306434 and parameters: {'n_estimators': 106, 'max_depth': 9, 'learning_rate': 0.045679697659303485, 'subsample': 0.8412638448995651, 'colsample_bytree': 0.6493071381190736, 'lambda': 0.015500606468849501, 'alpha': 0.26628123590189157}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:40,567] Trial 48 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 971, 'max_depth': 10, 'learning_rate': 0.031187050027382517, 'subsample': 0.8877715932773886, 'colsample_bytree': 0.5871051649510581, 'lambda': 0.003450638910194934, 'alpha': 0.02770219811153655}. Best is trial 37 with value: 0.8724100327153762.\n",
            "<ipython-input-3-aa0f503babcb>:40: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
            "<ipython-input-3-aa0f503babcb>:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
            "<ipython-input-3-aa0f503babcb>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
            "[I 2024-10-19 18:12:45,146] Trial 49 finished with value: 0.8571428571428571 and parameters: {'n_estimators': 227, 'max_depth': 11, 'learning_rate': 0.03983385239294324, 'subsample': 0.7160804574387121, 'colsample_bytree': 0.5559957633680426, 'lambda': 0.035416508575106045, 'alpha': 0.0019070409465621998}. Best is trial 37 with value: 0.8724100327153762.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 160, 'max_depth': 12, 'learning_rate': 0.06806890658910449, 'subsample': 0.9995021266803916, 'colsample_bytree': 0.6285817854072765, 'lambda': 0.11019480721665534, 'alpha': 0.005958951726100463}\n",
            "Predictions saved to submission_optuna.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb4STS9TAEph",
        "outputId": "8d47a109-8dce-48de-829f-7800964a9083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category-encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb1IGz7MAgEg",
        "outputId": "e1d5a4ef-84c5-412d-c7b9-0a5ffad8863d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category-encoders\n",
            "  Downloading category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.14.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2024.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category-encoders) (24.1)\n",
            "Downloading category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Memory Management: The code optimizes the data types and uses a subset of the training data to manage memory consumption effectively.\n",
        "* Preprocessing: It includes target encoding for categorical features and scales numeric features.\n",
        "* Polynomial Features: Polynomial features are applied with interactions only, helping to reduce dimensionality.\n",
        "* Optuna Integration: It includes a hyperparameter tuning setup using Optuna for the XGBoost model.\n",
        "* Stacking Classifier: It combines predictions from XGBoost, LightGBM, and CatBoost for better performance."
      ],
      "metadata": {
        "id": "jywzn9KWDrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5P6_R6TGsA_",
        "outputId": "442a1350-5969-42d3-8b54-c98637c8f7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxpIao-7Hb_P",
        "outputId": "1933c472-a232-4802-a2c6-9d9c469a9d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1096"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy2umqn7IxjF",
        "outputId": "869c85a7-7733-462b-ba3a-26f4ffec8ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111346"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "CweYa5lUNxsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "import time\n",
        "import gc\n",
        "\n",
        "# Function to monitor time\n",
        "class MonitorTime:\n",
        "    def __init__(self, step):\n",
        "        self.step = step\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start_time = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        end_time = time.time()\n",
        "        print(f\"{self.step} took {end_time - self.start_time:.2f} seconds\")\n",
        "\n",
        "# Load the data\n",
        "with MonitorTime(\"Loading data\"):\n",
        "    train_data = pd.read_csv('train_data.csv')  # Use full data for training\n",
        "    test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "with MonitorTime(\"Splitting data\"):\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "def create_preprocessor():\n",
        "    with MonitorTime(\"Creating preprocessor\"):\n",
        "        preprocessor = ColumnTransformer([\n",
        "            ('target_encode', ce.TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "            ('scaler', StandardScaler(), numeric_columns)\n",
        "        ])\n",
        "    return preprocessor\n",
        "\n",
        "preprocessor = create_preprocessor()\n",
        "\n",
        "# Fit and transform the training data with target encoding\n",
        "with MonitorTime(\"Applying target encoding\"):\n",
        "    X_train_transformed = preprocessor.fit_transform(X_train, y_train)\n",
        "    X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'device': 'gpu',\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),  # Wider range\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),  # Increased max depth\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),  # Broader range\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-5, 10.0, log=True),  # Broader range\n",
        "        'alpha': trial.suggest_float('alpha', 1e-5, 10.0, log=True)   # Broader range\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(**param)\n",
        "    model.fit(X_train_transformed, y_train)\n",
        "    return model.score(X_valid_transformed, y_valid)\n",
        "\n",
        "# Create Optuna study for hyperparameter tuning\n",
        "with MonitorTime(\"Running Optuna study\"):\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=20)  # Limit trials to manage memory\n",
        "\n",
        "# Display best hyperparameters\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "\n",
        "# Train best XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(**study.best_params)\n",
        "with MonitorTime(\"Training final XGBoost model\"):\n",
        "    xgb_model.fit(X_train_transformed, y_train)\n",
        "\n",
        "# Feature Importance Plot\n",
        "with MonitorTime(\"Plotting feature importance\"):\n",
        "    xgb.plot_importance(xgb_model)\n",
        "    plt.show()\n",
        "\n",
        "# Prepare test data for prediction\n",
        "with MonitorTime(\"Preparing test data\"):\n",
        "    test_data_encoded = preprocessor.transform(test_data)\n",
        "\n",
        "# CatBoost Classifier\n",
        "catboost_model = CatBoostClassifier(task_type='GPU', verbose=0)  # CatBoost with GPU\n",
        "\n",
        "# Stacking model\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=[('xgb', xgb_model), ('catboost', catboost_model)],\n",
        "    final_estimator=xgb.XGBClassifier()  # Using XGBoost as the final estimator\n",
        ")\n",
        "\n",
        "# Train and predict using stacking\n",
        "with MonitorTime(\"Training stacking model\"):\n",
        "    stacked_model.fit(X_train_transformed, y_train)\n",
        "\n",
        "with MonitorTime(\"Making predictions\"):\n",
        "    test_predictions = stacked_model.predict(test_data_encoded)\n",
        "\n",
        "# Save predictions for submission\n",
        "with MonitorTime(\"Saving predictions\"):\n",
        "    submission_df = pd.DataFrame({\n",
        "        'id': test_data.index,\n",
        "        'output': test_predictions\n",
        "    })\n",
        "    submission_df.to_csv('submission_stacked.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_stacked2.csv\")\n",
        "\n",
        "# Clean up memory\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4hwEvQiIwhQ",
        "outputId": "fc768f63-bab6-4311-9c8c-08bfc156ea72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-19 19:18:08,831] A new study created in memory with name: no-name-34f5de8d-b518-4abc-b92f-f7a5886c8a75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data took 0.54 seconds\n",
            "Splitting data took 0.01 seconds\n",
            "Creating preprocessor took 0.00 seconds\n",
            "Applying target encoding took 0.10 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-19 19:18:11,160] Trial 0 finished with value: 0.8538713195201745 and parameters: {'n_estimators': 776, 'max_depth': 3, 'learning_rate': 0.04353396078675053, 'subsample': 0.5039884802499481, 'colsample_bytree': 0.8838428159709926, 'lambda': 0.023868234768160555, 'alpha': 0.087621776680293}. Best is trial 0 with value: 0.8538713195201745.\n",
            "[I 2024-10-19 19:18:17,406] Trial 1 finished with value: 0.8407851690294439 and parameters: {'n_estimators': 319, 'max_depth': 9, 'learning_rate': 0.002831956461430996, 'subsample': 0.7380920520451759, 'colsample_bytree': 0.6645893938266938, 'lambda': 0.5319219126984857, 'alpha': 5.382835728697154}. Best is trial 0 with value: 0.8538713195201745.\n",
            "[I 2024-10-19 19:18:18,717] Trial 2 finished with value: 0.8386041439476554 and parameters: {'n_estimators': 498, 'max_depth': 3, 'learning_rate': 0.0015340798339090504, 'subsample': 0.626835598416845, 'colsample_bytree': 0.7391119959318266, 'lambda': 0.0003108046901624853, 'alpha': 0.6936008876221961}. Best is trial 0 with value: 0.8538713195201745.\n",
            "[I 2024-10-19 19:18:27,285] Trial 3 finished with value: 0.8571428571428571 and parameters: {'n_estimators': 1130, 'max_depth': 14, 'learning_rate': 0.16946453772074938, 'subsample': 0.706944220171168, 'colsample_bytree': 0.6314207710790593, 'lambda': 6.635022018091383e-05, 'alpha': 0.15831752853519643}. Best is trial 3 with value: 0.8571428571428571.\n",
            "[I 2024-10-19 19:18:30,783] Trial 4 finished with value: 0.8593238822246456 and parameters: {'n_estimators': 916, 'max_depth': 7, 'learning_rate': 0.2642041580451899, 'subsample': 0.7702423266813991, 'colsample_bytree': 0.8320456718157465, 'lambda': 0.006101016097933144, 'alpha': 0.006069020160319749}. Best is trial 4 with value: 0.8593238822246456.\n",
            "[I 2024-10-19 19:18:35,739] Trial 5 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 452, 'max_depth': 15, 'learning_rate': 0.11196547585722057, 'subsample': 0.6773065113269046, 'colsample_bytree': 0.6236083180229823, 'lambda': 0.25718040049102564, 'alpha': 0.01011232839940664}. Best is trial 4 with value: 0.8593238822246456.\n",
            "[I 2024-10-19 19:18:40,116] Trial 6 finished with value: 0.8582333696837514 and parameters: {'n_estimators': 319, 'max_depth': 8, 'learning_rate': 0.037925150485235086, 'subsample': 0.6328760500811155, 'colsample_bytree': 0.7457712023630055, 'lambda': 0.41409839157986095, 'alpha': 0.008770402709084316}. Best is trial 4 with value: 0.8593238822246456.\n",
            "[I 2024-10-19 19:19:11,897] Trial 7 finished with value: 0.8560523446019629 and parameters: {'n_estimators': 791, 'max_depth': 14, 'learning_rate': 0.004141452202459492, 'subsample': 0.9753281630681238, 'colsample_bytree': 0.8212144272687903, 'lambda': 8.658803044229726, 'alpha': 1.3308855961322703}. Best is trial 4 with value: 0.8593238822246456.\n",
            "[I 2024-10-19 19:19:13,602] Trial 8 finished with value: 0.8538713195201745 and parameters: {'n_estimators': 518, 'max_depth': 4, 'learning_rate': 0.031487803287417536, 'subsample': 0.5608290074949515, 'colsample_bytree': 0.5104353776114773, 'lambda': 0.00013942953116310398, 'alpha': 0.008697060278327864}. Best is trial 4 with value: 0.8593238822246456.\n",
            "[I 2024-10-19 19:19:23,717] Trial 9 finished with value: 0.8538713195201745 and parameters: {'n_estimators': 903, 'max_depth': 12, 'learning_rate': 0.029298984979500894, 'subsample': 0.6664395175700621, 'colsample_bytree': 0.6993049184478559, 'lambda': 1.1258842560053722e-05, 'alpha': 7.804785634854904}. Best is trial 4 with value: 0.8593238822246456.\n",
            "[I 2024-10-19 19:19:36,853] Trial 10 finished with value: 0.8680479825517994 and parameters: {'n_estimators': 1409, 'max_depth': 6, 'learning_rate': 0.010271183666581949, 'subsample': 0.8583749136186822, 'colsample_bytree': 0.9988309346665843, 'lambda': 0.003062102714269216, 'alpha': 5.338599128652177e-05}. Best is trial 10 with value: 0.8680479825517994.\n",
            "[I 2024-10-19 19:19:49,858] Trial 11 finished with value: 0.8658669574700109 and parameters: {'n_estimators': 1489, 'max_depth': 6, 'learning_rate': 0.010212339375801117, 'subsample': 0.8605171970399402, 'colsample_bytree': 0.9983318414930633, 'lambda': 0.004509005144692937, 'alpha': 1.7480368513390988e-05}. Best is trial 10 with value: 0.8680479825517994.\n",
            "[I 2024-10-19 19:20:03,781] Trial 12 finished with value: 0.8702290076335878 and parameters: {'n_estimators': 1462, 'max_depth': 6, 'learning_rate': 0.008252647239585268, 'subsample': 0.8798353150886109, 'colsample_bytree': 0.9915078582609945, 'lambda': 0.0021412922470020242, 'alpha': 1.1851271361097405e-05}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:20:13,386] Trial 13 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 1492, 'max_depth': 5, 'learning_rate': 0.008962531395197029, 'subsample': 0.8942799428503623, 'colsample_bytree': 0.9983120312430457, 'lambda': 0.0012101036094909787, 'alpha': 1.0458550460983804e-05}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:20:42,617] Trial 14 finished with value: 0.8658669574700109 and parameters: {'n_estimators': 1240, 'max_depth': 11, 'learning_rate': 0.007379923151464704, 'subsample': 0.8474279167639371, 'colsample_bytree': 0.9273789015114395, 'lambda': 0.028545419931855838, 'alpha': 0.00022186306770208153}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:20:53,584] Trial 15 finished with value: 0.8691384950926936 and parameters: {'n_estimators': 1286, 'max_depth': 6, 'learning_rate': 0.016826913215230756, 'subsample': 0.9919875593456059, 'colsample_bytree': 0.932584269319184, 'lambda': 0.0008440235900511421, 'alpha': 0.00013271710692551938}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:21:04,754] Trial 16 finished with value: 0.8636859323882224 and parameters: {'n_estimators': 1213, 'max_depth': 10, 'learning_rate': 0.07664684828016506, 'subsample': 0.9816721447705694, 'colsample_bytree': 0.9282701194894479, 'lambda': 0.0009976617073579348, 'alpha': 0.0003531850026053337}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:21:20,897] Trial 17 finished with value: 0.8658669574700109 and parameters: {'n_estimators': 1322, 'max_depth': 8, 'learning_rate': 0.015829346886564143, 'subsample': 0.9335041348584505, 'colsample_bytree': 0.9179194178132231, 'lambda': 3.173352657302952e-05, 'alpha': 0.0005989378631690782}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:21:27,859] Trial 18 finished with value: 0.8702290076335878 and parameters: {'n_estimators': 1062, 'max_depth': 5, 'learning_rate': 0.0037558713574506503, 'subsample': 0.9991764984580919, 'colsample_bytree': 0.8342562597640455, 'lambda': 0.0003643975492789433, 'alpha': 7.678984949143699e-05}. Best is trial 12 with value: 0.8702290076335878.\n",
            "[I 2024-10-19 19:21:34,799] Trial 19 finished with value: 0.8538713195201745 and parameters: {'n_estimators': 1053, 'max_depth': 5, 'learning_rate': 0.0011197845750576193, 'subsample': 0.8043641621660212, 'colsample_bytree': 0.8016958452051532, 'lambda': 0.04064499454695009, 'alpha': 0.001780606708364923}. Best is trial 12 with value: 0.8702290076335878.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Optuna study took 205.97 seconds\n",
            "Best Hyperparameters: {'n_estimators': 1462, 'max_depth': 6, 'learning_rate': 0.008252647239585268, 'subsample': 0.8798353150886109, 'colsample_bytree': 0.9915078582609945, 'lambda': 0.0021412922470020242, 'alpha': 1.1851271361097405e-05}\n",
            "Training final XGBoost model took 55.63 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting feature importance took 4.16 seconds\n",
            "Preparing test data took 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 5649.0625 Total: 15102.0625\n",
            "Warning: less than 75% GPU memory available for training. Free: 5649.0625 Total: 15102.0625\n",
            "Warning: less than 75% GPU memory available for training. Free: 5649.0625 Total: 15102.0625\n",
            "Warning: less than 75% GPU memory available for training. Free: 5649.0625 Total: 15102.0625\n",
            "Warning: less than 75% GPU memory available for training. Free: 5649.0625 Total: 15102.0625\n",
            "Warning: less than 75% GPU memory available for training. Free: 5649.0625 Total: 15102.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training stacking model took 577.64 seconds\n",
            "Making predictions took 0.05 seconds\n",
            "Saving predictions took 0.00 seconds\n",
            "Predictions saved to submission_stacked2.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119706"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of xgboost and other enhancement do not very different test results than in past."
      ],
      "metadata": {
        "id": "FVtlo0VJGn5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As training data has imbalance with label 0 being minority class, trying SMOTE to mitigate data imbalance"
      ],
      "metadata": {
        "id": "P37ENNDrGx2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfQi2IoRQLVp",
        "outputId": "9a35d8e5-9d39-472f-fafb-e720e822c026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('target_encode', TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train, y_train)  # Pass y_train here\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Train XGBoost model with balanced data and specified hyperparameters\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=1462,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.008252647239585268,\n",
        "    subsample=0.8798353150886109,\n",
        "    colsample_bytree=0.9915078582609945,\n",
        "    reg_lambda=0.0021412922470020242,  # Fixed from lambda to reg_lambda\n",
        "    alpha=1.1851271361097405e-05,\n",
        "    scale_pos_weight=1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'  # Set an appropriate evaluation metric\n",
        ")\n",
        "\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Validate the model\n",
        "y_pred = model.predict(X_valid_transformed)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Prepare test data for prediction\n",
        "test_data_transformed = preprocessor.transform(test_data)\n",
        "test_predictions = model.predict(test_data_transformed)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission_df.to_csv('submission_xgb_smote.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_xgb_smote.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJcQMAQKOrDy",
        "outputId": "36255d82-8638-49ff-9eb3-0edfd9074572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8669574700109052\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.37      0.47       148\n",
            "           1       0.89      0.96      0.92       769\n",
            "\n",
            "    accuracy                           0.87       917\n",
            "   macro avg       0.77      0.67      0.70       917\n",
            "weighted avg       0.85      0.87      0.85       917\n",
            "\n",
            "Predictions saved to submission_xgb_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rumXIey9S88-",
        "outputId": "04548d58-45cc-44e0-85a4-6930d5c9a473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This improves test accuracy from 54% to 61%. So this is a good direction."
      ],
      "metadata": {
        "id": "N1X0DLvZG-qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying neural networks to see if that helps improve test accuracy"
      ],
      "metadata": {
        "id": "W_n2eKVsHKGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV4FKr28ig2W",
        "outputId": "befb9af3-f997-45da-b115-30959c1dbf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load your data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Check for non-numeric columns\n",
        "print(train_data.dtypes)\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_columns),\n",
        "    ('cat', OneHotEncoder(), categorical_columns)\n",
        "])\n",
        "\n",
        "# Apply the preprocessing to your dataset\n",
        "X_transformed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data into tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train).float()\n",
        "y_train_tensor = torch.tensor(y_train.values).long()\n",
        "\n",
        "X_valid_tensor = torch.tensor(X_valid).float()\n",
        "y_valid_tensor = torch.tensor(y_valid.values).long()\n",
        "\n",
        "# Create DataLoader for PyTorch\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "\n",
        "# Define the neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 64\n",
        "num_classes = len(y.unique())  # Number of output classes\n",
        "model = SimpleNN(input_size, hidden_size, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "# Evaluation on validation data\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valid_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzimwjJhhTY0",
        "outputId": "a3169958-2c62-4857-f070-ee586544b1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1           int64\n",
            "x2           int64\n",
            "x3           int64\n",
            "x4           int64\n",
            "x5         float64\n",
            "            ...   \n",
            "z222       float64\n",
            "subject     object\n",
            "phase        int64\n",
            "state       object\n",
            "output       int64\n",
            "Length: 670, dtype: object\n",
            "Epoch [1/20], Loss: 0.4246436735858088\n",
            "Epoch [2/20], Loss: 0.3701604314472364\n",
            "Epoch [3/20], Loss: 0.33908496771169744\n",
            "Epoch [4/20], Loss: 0.31109429792217586\n",
            "Epoch [5/20], Loss: 0.29127054719821266\n",
            "Epoch [6/20], Loss: 0.2687688674615777\n",
            "Epoch [7/20], Loss: 0.24375930078651595\n",
            "Epoch [8/20], Loss: 0.22506670653820038\n",
            "Epoch [9/20], Loss: 0.20976838012752325\n",
            "Epoch [10/20], Loss: 0.2032266502795012\n",
            "Epoch [11/20], Loss: 0.17374949678778648\n",
            "Epoch [12/20], Loss: 0.15724096431032472\n",
            "Epoch [13/20], Loss: 0.15463693608408388\n",
            "Epoch [14/20], Loss: 0.14880875860867293\n",
            "Epoch [15/20], Loss: 0.1248208956549997\n",
            "Epoch [16/20], Loss: 0.11637893782361694\n",
            "Epoch [17/20], Loss: 0.1089136201078477\n",
            "Epoch [18/20], Loss: 0.09965925351109194\n",
            "Epoch [19/20], Loss: 0.0850598821659451\n",
            "Epoch [20/20], Loss: 0.08715752006062995\n",
            "Validation Accuracy: 84.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load your data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numeric_columns),\n",
        "    ('cat', OneHotEncoder(), categorical_columns)\n",
        "])\n",
        "\n",
        "# Apply the preprocessing to your dataset\n",
        "X_transformed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data into tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train).float()\n",
        "y_train_tensor = torch.tensor(y_train.values).long()\n",
        "\n",
        "X_valid_tensor = torch.tensor(X_valid).float()\n",
        "y_valid_tensor = torch.tensor(y_valid.values).long()\n",
        "\n",
        "# Create DataLoader for PyTorch\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64)\n",
        "\n",
        "# Define the enhanced neural network\n",
        "class EnhancedNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(EnhancedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size // 2)\n",
        "\n",
        "        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 128  # Increased size of the hidden layer\n",
        "num_classes = len(y.unique())  # Number of output classes\n",
        "model = EnhancedNN(input_size, hidden_size, num_classes)\n",
        "\n",
        "# Use Adam optimizer with weight decay (L2 regularization)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Training loop with improvements\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()  # Update the learning rate\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "# Evaluation on validation data\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valid_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpy0d5gWjgOS",
        "outputId": "e7c837a7-6bdd-4b2a-b48b-29b0184175ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.46917218946177386\n",
            "Epoch [2/20], Loss: 0.4021368383847434\n",
            "Epoch [3/20], Loss: 0.3878478865171301\n",
            "Epoch [4/20], Loss: 0.3710547539180723\n",
            "Epoch [5/20], Loss: 0.3606165914699949\n",
            "Epoch [6/20], Loss: 0.3358851619835558\n",
            "Epoch [7/20], Loss: 0.32835103674181576\n",
            "Epoch [8/20], Loss: 0.3169963801729268\n",
            "Epoch [9/20], Loss: 0.3129342134142744\n",
            "Epoch [10/20], Loss: 0.29698213189840317\n",
            "Epoch [11/20], Loss: 0.28886267619914024\n",
            "Epoch [12/20], Loss: 0.2806277359867918\n",
            "Epoch [13/20], Loss: 0.2657181251922558\n",
            "Epoch [14/20], Loss: 0.2689751563914891\n",
            "Epoch [15/20], Loss: 0.2612591352442215\n",
            "Epoch [16/20], Loss: 0.25263171720093697\n",
            "Epoch [17/20], Loss: 0.24809935020989385\n",
            "Epoch [18/20], Loss: 0.2503225600411152\n",
            "Epoch [19/20], Loss: 0.24254371123067264\n",
            "Epoch [20/20], Loss: 0.24577735724120303\n",
            "Validation Accuracy: 84.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This did not lead to any improvement in test accuracy"
      ],
      "metadata": {
        "id": "953TDosYHdQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torch torchvision\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline with handle_unknown parameter\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Transform the data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "X_test_transformed = preprocessor.transform(test_data)\n",
        "\n",
        "# Convert the data into PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_transformed)  # No need for .toarray() here\n",
        "y_train_tensor = torch.LongTensor(y_train.values)\n",
        "X_valid_tensor = torch.FloatTensor(X_valid_transformed)\n",
        "y_valid_tensor = torch.LongTensor(y_valid.values)\n",
        "X_test_tensor = torch.FloatTensor(X_test_transformed)\n",
        "\n",
        "# Create a Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "valid_dataset = CustomDataset(X_valid_tensor, y_valid_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor, None)  # No labels for test data\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the Neural Network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)  # Adjust the output layer for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define the loss function and optimizer\n",
        "model = SimpleNN(X_train_tensor.shape[1])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_outputs = model(X_valid_tensor)\n",
        "        _, predicted = torch.max(valid_outputs, 1)\n",
        "        acc = (predicted == y_valid_tensor).float().mean()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc.item()*100:.2f}%')\n",
        "\n",
        "# Prepare test data predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,  # Assuming the test data has an index or unique ID\n",
        "    'output': test_predictions.numpy()  # Convert tensor to numpy array\n",
        "})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X71dO031kW9j",
        "outputId": "8125da53-c55c-4f6c-dd3a-0056c305f692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Epoch [1/20], Loss: 0.3076, Validation Accuracy: 83.86%\n",
            "Epoch [2/20], Loss: 0.3692, Validation Accuracy: 83.75%\n",
            "Epoch [3/20], Loss: 0.3993, Validation Accuracy: 84.62%\n",
            "Epoch [4/20], Loss: 0.1882, Validation Accuracy: 83.97%\n",
            "Epoch [5/20], Loss: 0.5604, Validation Accuracy: 84.51%\n",
            "Epoch [6/20], Loss: 0.4467, Validation Accuracy: 84.30%\n",
            "Epoch [7/20], Loss: 0.3913, Validation Accuracy: 83.97%\n",
            "Epoch [8/20], Loss: 0.2076, Validation Accuracy: 83.97%\n",
            "Epoch [9/20], Loss: 0.1128, Validation Accuracy: 83.97%\n",
            "Epoch [10/20], Loss: 0.3575, Validation Accuracy: 83.42%\n",
            "Epoch [11/20], Loss: 0.0947, Validation Accuracy: 83.42%\n",
            "Epoch [12/20], Loss: 0.1783, Validation Accuracy: 82.01%\n",
            "Epoch [13/20], Loss: 0.0425, Validation Accuracy: 82.99%\n",
            "Epoch [14/20], Loss: 0.3540, Validation Accuracy: 82.33%\n",
            "Epoch [15/20], Loss: 0.0652, Validation Accuracy: 82.55%\n",
            "Epoch [16/20], Loss: 0.0604, Validation Accuracy: 82.77%\n",
            "Epoch [17/20], Loss: 0.0310, Validation Accuracy: 83.42%\n",
            "Epoch [18/20], Loss: 0.1451, Validation Accuracy: 83.10%\n",
            "Epoch [19/20], Loss: 0.0464, Validation Accuracy: 83.42%\n",
            "Epoch [20/20], Loss: 0.0838, Validation Accuracy: 83.86%\n",
            "Predictions saved to submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odtEDcIWaWA8",
        "outputId": "0d0ffe26-5131-4f74-e0c0-7b3b49550918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
            "Downloading category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/82.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out feature selection to see if that helps"
      ],
      "metadata": {
        "id": "5gjVSA7aHsik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('target_encode', TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train, y_train)  # Pass y_train here\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Feature selection using XGBoost\n",
        "xgb_fs = xgb.XGBClassifier(\n",
        "    n_estimators=1462,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.008252647239585268,\n",
        "    subsample=0.8798353150886109,\n",
        "    colsample_bytree=0.9915078582609945,\n",
        "    reg_lambda=0.0021412922470020242,\n",
        "    alpha=1.1851271361097405e-05,\n",
        "    scale_pos_weight=3,  # Adjusted for class imbalance\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_fs.fit(X_train_balanced, y_train_balanced)\n",
        "selector = SelectFromModel(xgb_fs, prefit=True)\n",
        "\n",
        "# Select important features\n",
        "X_train_selected = selector.transform(X_train_balanced)\n",
        "X_valid_selected = selector.transform(X_valid_transformed)\n",
        "\n",
        "# Train final XGBoost model with selected features\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=1462,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.008252647239585268,\n",
        "    subsample=0.8798353150886109,\n",
        "    colsample_bytree=0.9915078582609945,\n",
        "    reg_lambda=0.0021412922470020242,\n",
        "    alpha=1.1851271361097405e-05,\n",
        "    scale_pos_weight=3,  # Adjusted for class imbalance\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "model.fit(X_train_selected, y_train_balanced)\n",
        "\n",
        "# Validate the model\n",
        "y_pred = model.predict(X_valid_selected)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Prepare test data for prediction\n",
        "test_data_transformed = preprocessor.transform(test_data)\n",
        "test_data_selected = selector.transform(test_data_transformed)\n",
        "test_predictions = model.predict(test_data_selected)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission_df.to_csv('submission_xgb_fs_smote.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_xgb_fs_smote.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNQ04DqbaSFO",
        "outputId": "f1ea7db6-8c17-4ba4-bfc4-c235fea5678a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8604143947655398\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.23      0.35       148\n",
            "           1       0.87      0.98      0.92       769\n",
            "\n",
            "    accuracy                           0.86       917\n",
            "   macro avg       0.79      0.61      0.63       917\n",
            "weighted avg       0.84      0.86      0.83       917\n",
            "\n",
            "Predictions saved to submission_xgb_fs_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This leads to reduction in recall of label 0"
      ],
      "metadata": {
        "id": "N2X3P3EBH1mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out lasso to reduce features"
      ],
      "metadata": {
        "id": "WZc2sd9IH-s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('target_encode', TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train, y_train)  # Pass y_train here\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Feature selection using LassoCV (L1 regularization)\n",
        "lasso = LassoCV(cv=5, random_state=42).fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Select important features\n",
        "lasso_selector = SelectFromModel(lasso, prefit=True)\n",
        "X_train_lasso_selected = lasso_selector.transform(X_train_balanced)\n",
        "X_valid_lasso_selected = lasso_selector.transform(X_valid_transformed)\n",
        "\n",
        "# Train final XGBoost model with selected features\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=1462,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.008252647239585268,\n",
        "    subsample=0.8798353150886109,\n",
        "    colsample_bytree=0.9915078582609945,\n",
        "    reg_lambda=0.0021412922470020242,\n",
        "    alpha=1.1851271361097405e-05,\n",
        "    scale_pos_weight=4,  # Focus more on minority class\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "model.fit(X_train_lasso_selected, y_train_balanced)\n",
        "\n",
        "# Validate the model\n",
        "y_pred = model.predict(X_valid_lasso_selected)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Prepare test data for prediction\n",
        "test_data_transformed = preprocessor.transform(test_data)\n",
        "test_data_lasso_selected = lasso_selector.transform(test_data_transformed)\n",
        "test_predictions = model.predict(test_data_lasso_selected)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission_df.to_csv('submission_xgb_lasso_smote.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_xgb_lasso_smote.csv\")"
      ],
      "metadata": {
        "id": "zAXF-kI8lw5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddc7955-091d-4cb5-dc4a-9fef17f5e2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8538713195201745\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.19      0.29       148\n",
            "           1       0.86      0.98      0.92       769\n",
            "\n",
            "    accuracy                           0.85       917\n",
            "   macro avg       0.76      0.59      0.61       917\n",
            "weighted avg       0.83      0.85      0.82       917\n",
            "\n",
            "Predictions saved to submission_xgb_lasso_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This reduces label 0 recall further to 19%"
      ],
      "metadata": {
        "id": "QyufA2MNIEwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out focal loss to add higher importance to minority class to get right  "
      ],
      "metadata": {
        "id": "ej2JkguqIOCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Custom Focal Loss Objective for XGBoost\n",
        "def focal_loss(alpha, gamma):\n",
        "    def focal_loss_obj(preds, dtrain):\n",
        "        labels = dtrain.get_label()\n",
        "        preds = 1.0 / (1.0 + np.exp(-preds))  # Sigmoid\n",
        "        loss = -alpha * labels * np.power(1 - preds, gamma) * np.log(preds) - \\\n",
        "               (1 - alpha) * (1 - labels) * np.power(preds, gamma) * np.log(1 - preds)\n",
        "        grad = alpha * (preds - labels) * np.power(1 - preds, gamma - 1) * gamma\n",
        "        hess = alpha * np.power(1 - preds, gamma - 1) * (1 - 2 * preds) * gamma + grad * (1 - grad)\n",
        "        return grad, hess\n",
        "    return focal_loss_obj\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('target_encode', TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train, y_train)  # Pass y_train here\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Feature selection using SelectFromModel\n",
        "xgb_fs = xgb.XGBClassifier(\n",
        "    n_estimators=1462,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.008252647239585268,\n",
        "    subsample=0.8798353150886109,\n",
        "    colsample_bytree=0.9915078582609945,\n",
        "    reg_lambda=0.0021412922470020242,\n",
        "    alpha=1.1851271361097405e-05,\n",
        "    scale_pos_weight=10,  # Significantly increased to focus on label 0\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_fs.fit(X_train_balanced, y_train_balanced)\n",
        "selector = SelectFromModel(xgb_fs, prefit=True)\n",
        "\n",
        "# Select important features\n",
        "X_train_selected = selector.transform(X_train_balanced)\n",
        "X_valid_selected = selector.transform(X_valid_transformed)\n",
        "\n",
        "# Convert data to DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train_selected, label=y_train_balanced)\n",
        "dvalid = xgb.DMatrix(X_valid_selected, label=y_valid)\n",
        "\n",
        "# Parameters (without the custom objective here)\n",
        "params = {\n",
        "    'eval_metric': 'logloss',\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.008252647239585268,\n",
        "    'subsample': 0.8798353150886109,\n",
        "    'colsample_bytree': 0.9915078582609945,\n",
        "    'reg_lambda': 0.0021412922470020242,\n",
        "    'alpha': 1.1851271361097405e-05,\n",
        "    'scale_pos_weight': 10,\n",
        "    'seed': 42,\n",
        "    'silent': 1\n",
        "}\n",
        "\n",
        "# Custom training loop with Focal Loss objective\n",
        "evallist = [(dvalid, 'eval')]\n",
        "bst = xgb.train(params, dtrain, num_boost_round=1462, evals=evallist, obj=focal_loss(alpha=0.25, gamma=2))\n",
        "\n",
        "# Validate the model\n",
        "y_pred = bst.predict(dvalid)\n",
        "y_pred_labels = np.where(y_pred > 0.5, 1, 0)  # Convert probabilities to binary labels\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred_labels))\n",
        "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_labels))\n",
        "\n",
        "# Prepare test data for prediction\n",
        "test_data_transformed = preprocessor.transform(test_data)\n",
        "test_data_selected = selector.transform(test_data_transformed)\n",
        "dtest = xgb.DMatrix(test_data_selected)\n",
        "test_predictions = bst.predict(dtest)\n",
        "test_predictions_labels = np.where(test_predictions > 0.5, 1, 0)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions_labels\n",
        "})\n",
        "submission_df.to_csv('submission_xgb_focal_smote_dmatrix.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_xgb_focal_smote_dmatrix.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_oXku1jdFgU",
        "outputId": "86e42a52-793f-43ab-f79a-05efc9e3d263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\teval-logloss:0.69315\n",
            "[1]\teval-logloss:0.69315\n",
            "[2]\teval-logloss:0.69315\n",
            "[3]\teval-logloss:0.69315\n",
            "[4]\teval-logloss:0.69315\n",
            "[5]\teval-logloss:0.69315\n",
            "[6]\teval-logloss:0.69315\n",
            "[7]\teval-logloss:0.69315\n",
            "[8]\teval-logloss:0.69315\n",
            "[9]\teval-logloss:0.69315\n",
            "[10]\teval-logloss:0.69315\n",
            "[11]\teval-logloss:0.69315\n",
            "[12]\teval-logloss:0.69315\n",
            "[13]\teval-logloss:0.69315\n",
            "[14]\teval-logloss:0.69315\n",
            "[15]\teval-logloss:0.69315\n",
            "[16]\teval-logloss:0.69315\n",
            "[17]\teval-logloss:0.69315\n",
            "[18]\teval-logloss:0.69315\n",
            "[19]\teval-logloss:0.69315\n",
            "[20]\teval-logloss:0.69315\n",
            "[21]\teval-logloss:0.69315\n",
            "[22]\teval-logloss:0.69315\n",
            "[23]\teval-logloss:0.69315\n",
            "[24]\teval-logloss:0.69315\n",
            "[25]\teval-logloss:0.69315\n",
            "[26]\teval-logloss:0.69315\n",
            "[27]\teval-logloss:0.69315\n",
            "[28]\teval-logloss:0.69315\n",
            "[29]\teval-logloss:0.69315\n",
            "[30]\teval-logloss:0.69315\n",
            "[31]\teval-logloss:0.69315\n",
            "[32]\teval-logloss:0.69315\n",
            "[33]\teval-logloss:0.69315\n",
            "[34]\teval-logloss:0.69315\n",
            "[35]\teval-logloss:0.69315\n",
            "[36]\teval-logloss:0.69315\n",
            "[37]\teval-logloss:0.69315\n",
            "[38]\teval-logloss:0.69315\n",
            "[39]\teval-logloss:0.69315\n",
            "[40]\teval-logloss:0.69315\n",
            "[41]\teval-logloss:0.69315\n",
            "[42]\teval-logloss:0.69315\n",
            "[43]\teval-logloss:0.69315\n",
            "[44]\teval-logloss:0.69315\n",
            "[45]\teval-logloss:0.69315\n",
            "[46]\teval-logloss:0.69315\n",
            "[47]\teval-logloss:0.69315\n",
            "[48]\teval-logloss:0.69315\n",
            "[49]\teval-logloss:0.69315\n",
            "[50]\teval-logloss:0.69315\n",
            "[51]\teval-logloss:0.69315\n",
            "[52]\teval-logloss:0.69315\n",
            "[53]\teval-logloss:0.69315\n",
            "[54]\teval-logloss:0.69315\n",
            "[55]\teval-logloss:0.69315\n",
            "[56]\teval-logloss:0.69315\n",
            "[57]\teval-logloss:0.69315\n",
            "[58]\teval-logloss:0.69315\n",
            "[59]\teval-logloss:0.69315\n",
            "[60]\teval-logloss:0.69315\n",
            "[61]\teval-logloss:0.69315\n",
            "[62]\teval-logloss:0.69315\n",
            "[63]\teval-logloss:0.69315\n",
            "[64]\teval-logloss:0.69315\n",
            "[65]\teval-logloss:0.69315\n",
            "[66]\teval-logloss:0.69315\n",
            "[67]\teval-logloss:0.69315\n",
            "[68]\teval-logloss:0.69315\n",
            "[69]\teval-logloss:0.69315\n",
            "[70]\teval-logloss:0.69315\n",
            "[71]\teval-logloss:0.69315\n",
            "[72]\teval-logloss:0.69315\n",
            "[73]\teval-logloss:0.69315\n",
            "[74]\teval-logloss:0.69315\n",
            "[75]\teval-logloss:0.69315\n",
            "[76]\teval-logloss:0.69315\n",
            "[77]\teval-logloss:0.69315\n",
            "[78]\teval-logloss:0.69315\n",
            "[79]\teval-logloss:0.69315\n",
            "[80]\teval-logloss:0.69315\n",
            "[81]\teval-logloss:0.69315\n",
            "[82]\teval-logloss:0.69315\n",
            "[83]\teval-logloss:0.69315\n",
            "[84]\teval-logloss:0.69315\n",
            "[85]\teval-logloss:0.69315\n",
            "[86]\teval-logloss:0.69315\n",
            "[87]\teval-logloss:0.69315\n",
            "[88]\teval-logloss:0.69315\n",
            "[89]\teval-logloss:0.69315\n",
            "[90]\teval-logloss:0.69315\n",
            "[91]\teval-logloss:0.69315\n",
            "[92]\teval-logloss:0.69315\n",
            "[93]\teval-logloss:0.69315\n",
            "[94]\teval-logloss:0.69315\n",
            "[95]\teval-logloss:0.69315\n",
            "[96]\teval-logloss:0.69315\n",
            "[97]\teval-logloss:0.69315\n",
            "[98]\teval-logloss:0.69315\n",
            "[99]\teval-logloss:0.69315\n",
            "[100]\teval-logloss:0.69315\n",
            "[101]\teval-logloss:0.69315\n",
            "[102]\teval-logloss:0.69315\n",
            "[103]\teval-logloss:0.69315\n",
            "[104]\teval-logloss:0.69315\n",
            "[105]\teval-logloss:0.69315\n",
            "[106]\teval-logloss:0.69315\n",
            "[107]\teval-logloss:0.69315\n",
            "[108]\teval-logloss:0.69315\n",
            "[109]\teval-logloss:0.69315\n",
            "[110]\teval-logloss:0.69315\n",
            "[111]\teval-logloss:0.69315\n",
            "[112]\teval-logloss:0.69315\n",
            "[113]\teval-logloss:0.69315\n",
            "[114]\teval-logloss:0.69315\n",
            "[115]\teval-logloss:0.69315\n",
            "[116]\teval-logloss:0.69315\n",
            "[117]\teval-logloss:0.69315\n",
            "[118]\teval-logloss:0.69315\n",
            "[119]\teval-logloss:0.69315\n",
            "[120]\teval-logloss:0.69315\n",
            "[121]\teval-logloss:0.69315\n",
            "[122]\teval-logloss:0.69315\n",
            "[123]\teval-logloss:0.69315\n",
            "[124]\teval-logloss:0.69315\n",
            "[125]\teval-logloss:0.69315\n",
            "[126]\teval-logloss:0.69315\n",
            "[127]\teval-logloss:0.69315\n",
            "[128]\teval-logloss:0.69315\n",
            "[129]\teval-logloss:0.69315\n",
            "[130]\teval-logloss:0.69315\n",
            "[131]\teval-logloss:0.69315\n",
            "[132]\teval-logloss:0.69315\n",
            "[133]\teval-logloss:0.69315\n",
            "[134]\teval-logloss:0.69315\n",
            "[135]\teval-logloss:0.69315\n",
            "[136]\teval-logloss:0.69315\n",
            "[137]\teval-logloss:0.69315\n",
            "[138]\teval-logloss:0.69315\n",
            "[139]\teval-logloss:0.69315\n",
            "[140]\teval-logloss:0.69315\n",
            "[141]\teval-logloss:0.69315\n",
            "[142]\teval-logloss:0.69315\n",
            "[143]\teval-logloss:0.69315\n",
            "[144]\teval-logloss:0.69315\n",
            "[145]\teval-logloss:0.69315\n",
            "[146]\teval-logloss:0.69315\n",
            "[147]\teval-logloss:0.69315\n",
            "[148]\teval-logloss:0.69315\n",
            "[149]\teval-logloss:0.69315\n",
            "[150]\teval-logloss:0.69315\n",
            "[151]\teval-logloss:0.69315\n",
            "[152]\teval-logloss:0.69315\n",
            "[153]\teval-logloss:0.69315\n",
            "[154]\teval-logloss:0.69315\n",
            "[155]\teval-logloss:0.69315\n",
            "[156]\teval-logloss:0.69315\n",
            "[157]\teval-logloss:0.69315\n",
            "[158]\teval-logloss:0.69315\n",
            "[159]\teval-logloss:0.69315\n",
            "[160]\teval-logloss:0.69315\n",
            "[161]\teval-logloss:0.69315\n",
            "[162]\teval-logloss:0.69315\n",
            "[163]\teval-logloss:0.69315\n",
            "[164]\teval-logloss:0.69315\n",
            "[165]\teval-logloss:0.69315\n",
            "[166]\teval-logloss:0.69315\n",
            "[167]\teval-logloss:0.69315\n",
            "[168]\teval-logloss:0.69315\n",
            "[169]\teval-logloss:0.69315\n",
            "[170]\teval-logloss:0.69315\n",
            "[171]\teval-logloss:0.69315\n",
            "[172]\teval-logloss:0.69315\n",
            "[173]\teval-logloss:0.69315\n",
            "[174]\teval-logloss:0.69315\n",
            "[175]\teval-logloss:0.69315\n",
            "[176]\teval-logloss:0.69315\n",
            "[177]\teval-logloss:0.69315\n",
            "[178]\teval-logloss:0.69315\n",
            "[179]\teval-logloss:0.69315\n",
            "[180]\teval-logloss:0.69315\n",
            "[181]\teval-logloss:0.69315\n",
            "[182]\teval-logloss:0.69315\n",
            "[183]\teval-logloss:0.69315\n",
            "[184]\teval-logloss:0.69315\n",
            "[185]\teval-logloss:0.69315\n",
            "[186]\teval-logloss:0.69315\n",
            "[187]\teval-logloss:0.69315\n",
            "[188]\teval-logloss:0.69315\n",
            "[189]\teval-logloss:0.69315\n",
            "[190]\teval-logloss:0.69315\n",
            "[191]\teval-logloss:0.69315\n",
            "[192]\teval-logloss:0.69315\n",
            "[193]\teval-logloss:0.69315\n",
            "[194]\teval-logloss:0.69315\n",
            "[195]\teval-logloss:0.69315\n",
            "[196]\teval-logloss:0.69315\n",
            "[197]\teval-logloss:0.69315\n",
            "[198]\teval-logloss:0.69315\n",
            "[199]\teval-logloss:0.69315\n",
            "[200]\teval-logloss:0.69315\n",
            "[201]\teval-logloss:0.69315\n",
            "[202]\teval-logloss:0.69315\n",
            "[203]\teval-logloss:0.69315\n",
            "[204]\teval-logloss:0.69315\n",
            "[205]\teval-logloss:0.69315\n",
            "[206]\teval-logloss:0.69315\n",
            "[207]\teval-logloss:0.69315\n",
            "[208]\teval-logloss:0.69315\n",
            "[209]\teval-logloss:0.69315\n",
            "[210]\teval-logloss:0.69315\n",
            "[211]\teval-logloss:0.69315\n",
            "[212]\teval-logloss:0.69315\n",
            "[213]\teval-logloss:0.69315\n",
            "[214]\teval-logloss:0.69315\n",
            "[215]\teval-logloss:0.69315\n",
            "[216]\teval-logloss:0.69315\n",
            "[217]\teval-logloss:0.69315\n",
            "[218]\teval-logloss:0.69315\n",
            "[219]\teval-logloss:0.69315\n",
            "[220]\teval-logloss:0.69315\n",
            "[221]\teval-logloss:0.69315\n",
            "[222]\teval-logloss:0.69315\n",
            "[223]\teval-logloss:0.69315\n",
            "[224]\teval-logloss:0.69315\n",
            "[225]\teval-logloss:0.69315\n",
            "[226]\teval-logloss:0.69315\n",
            "[227]\teval-logloss:0.69315\n",
            "[228]\teval-logloss:0.69315\n",
            "[229]\teval-logloss:0.69315\n",
            "[230]\teval-logloss:0.69315\n",
            "[231]\teval-logloss:0.69315\n",
            "[232]\teval-logloss:0.69315\n",
            "[233]\teval-logloss:0.69315\n",
            "[234]\teval-logloss:0.69315\n",
            "[235]\teval-logloss:0.69315\n",
            "[236]\teval-logloss:0.69315\n",
            "[237]\teval-logloss:0.69315\n",
            "[238]\teval-logloss:0.69315\n",
            "[239]\teval-logloss:0.69315\n",
            "[240]\teval-logloss:0.69315\n",
            "[241]\teval-logloss:0.69315\n",
            "[242]\teval-logloss:0.69315\n",
            "[243]\teval-logloss:0.69315\n",
            "[244]\teval-logloss:0.69315\n",
            "[245]\teval-logloss:0.69315\n",
            "[246]\teval-logloss:0.69315\n",
            "[247]\teval-logloss:0.69315\n",
            "[248]\teval-logloss:0.69315\n",
            "[249]\teval-logloss:0.69315\n",
            "[250]\teval-logloss:0.69315\n",
            "[251]\teval-logloss:0.69315\n",
            "[252]\teval-logloss:0.69315\n",
            "[253]\teval-logloss:0.69315\n",
            "[254]\teval-logloss:0.69315\n",
            "[255]\teval-logloss:0.69315\n",
            "[256]\teval-logloss:0.69315\n",
            "[257]\teval-logloss:0.69315\n",
            "[258]\teval-logloss:0.69315\n",
            "[259]\teval-logloss:0.69315\n",
            "[260]\teval-logloss:0.69315\n",
            "[261]\teval-logloss:0.69315\n",
            "[262]\teval-logloss:0.69315\n",
            "[263]\teval-logloss:0.69315\n",
            "[264]\teval-logloss:0.69315\n",
            "[265]\teval-logloss:0.69315\n",
            "[266]\teval-logloss:0.69315\n",
            "[267]\teval-logloss:0.69315\n",
            "[268]\teval-logloss:0.69315\n",
            "[269]\teval-logloss:0.69315\n",
            "[270]\teval-logloss:0.69315\n",
            "[271]\teval-logloss:0.69315\n",
            "[272]\teval-logloss:0.69315\n",
            "[273]\teval-logloss:0.69315\n",
            "[274]\teval-logloss:0.69315\n",
            "[275]\teval-logloss:0.69315\n",
            "[276]\teval-logloss:0.69315\n",
            "[277]\teval-logloss:0.69315\n",
            "[278]\teval-logloss:0.69315\n",
            "[279]\teval-logloss:0.69315\n",
            "[280]\teval-logloss:0.69315\n",
            "[281]\teval-logloss:0.69315\n",
            "[282]\teval-logloss:0.69315\n",
            "[283]\teval-logloss:0.69315\n",
            "[284]\teval-logloss:0.69315\n",
            "[285]\teval-logloss:0.69315\n",
            "[286]\teval-logloss:0.69315\n",
            "[287]\teval-logloss:0.69315\n",
            "[288]\teval-logloss:0.69315\n",
            "[289]\teval-logloss:0.69315\n",
            "[290]\teval-logloss:0.69315\n",
            "[291]\teval-logloss:0.69315\n",
            "[292]\teval-logloss:0.69315\n",
            "[293]\teval-logloss:0.69315\n",
            "[294]\teval-logloss:0.69315\n",
            "[295]\teval-logloss:0.69315\n",
            "[296]\teval-logloss:0.69315\n",
            "[297]\teval-logloss:0.69315\n",
            "[298]\teval-logloss:0.69315\n",
            "[299]\teval-logloss:0.69315\n",
            "[300]\teval-logloss:0.69315\n",
            "[301]\teval-logloss:0.69315\n",
            "[302]\teval-logloss:0.69315\n",
            "[303]\teval-logloss:0.69315\n",
            "[304]\teval-logloss:0.69315\n",
            "[305]\teval-logloss:0.69315\n",
            "[306]\teval-logloss:0.69315\n",
            "[307]\teval-logloss:0.69315\n",
            "[308]\teval-logloss:0.69315\n",
            "[309]\teval-logloss:0.69315\n",
            "[310]\teval-logloss:0.69315\n",
            "[311]\teval-logloss:0.69315\n",
            "[312]\teval-logloss:0.69315\n",
            "[313]\teval-logloss:0.69315\n",
            "[314]\teval-logloss:0.69315\n",
            "[315]\teval-logloss:0.69315\n",
            "[316]\teval-logloss:0.69315\n",
            "[317]\teval-logloss:0.69315\n",
            "[318]\teval-logloss:0.69315\n",
            "[319]\teval-logloss:0.69315\n",
            "[320]\teval-logloss:0.69315\n",
            "[321]\teval-logloss:0.69315\n",
            "[322]\teval-logloss:0.69315\n",
            "[323]\teval-logloss:0.69315\n",
            "[324]\teval-logloss:0.69315\n",
            "[325]\teval-logloss:0.69315\n",
            "[326]\teval-logloss:0.69315\n",
            "[327]\teval-logloss:0.69315\n",
            "[328]\teval-logloss:0.69315\n",
            "[329]\teval-logloss:0.69315\n",
            "[330]\teval-logloss:0.69315\n",
            "[331]\teval-logloss:0.69315\n",
            "[332]\teval-logloss:0.69315\n",
            "[333]\teval-logloss:0.69315\n",
            "[334]\teval-logloss:0.69315\n",
            "[335]\teval-logloss:0.69315\n",
            "[336]\teval-logloss:0.69315\n",
            "[337]\teval-logloss:0.69315\n",
            "[338]\teval-logloss:0.69315\n",
            "[339]\teval-logloss:0.69315\n",
            "[340]\teval-logloss:0.69315\n",
            "[341]\teval-logloss:0.69315\n",
            "[342]\teval-logloss:0.69315\n",
            "[343]\teval-logloss:0.69315\n",
            "[344]\teval-logloss:0.69315\n",
            "[345]\teval-logloss:0.69315\n",
            "[346]\teval-logloss:0.69315\n",
            "[347]\teval-logloss:0.69315\n",
            "[348]\teval-logloss:0.69315\n",
            "[349]\teval-logloss:0.69315\n",
            "[350]\teval-logloss:0.69315\n",
            "[351]\teval-logloss:0.69315\n",
            "[352]\teval-logloss:0.69315\n",
            "[353]\teval-logloss:0.69315\n",
            "[354]\teval-logloss:0.69315\n",
            "[355]\teval-logloss:0.69315\n",
            "[356]\teval-logloss:0.69315\n",
            "[357]\teval-logloss:0.69315\n",
            "[358]\teval-logloss:0.69315\n",
            "[359]\teval-logloss:0.69315\n",
            "[360]\teval-logloss:0.69315\n",
            "[361]\teval-logloss:0.69315\n",
            "[362]\teval-logloss:0.69315\n",
            "[363]\teval-logloss:0.69315\n",
            "[364]\teval-logloss:0.69315\n",
            "[365]\teval-logloss:0.69315\n",
            "[366]\teval-logloss:0.69315\n",
            "[367]\teval-logloss:0.69315\n",
            "[368]\teval-logloss:0.69315\n",
            "[369]\teval-logloss:0.69315\n",
            "[370]\teval-logloss:0.69315\n",
            "[371]\teval-logloss:0.69315\n",
            "[372]\teval-logloss:0.69315\n",
            "[373]\teval-logloss:0.69315\n",
            "[374]\teval-logloss:0.69315\n",
            "[375]\teval-logloss:0.69315\n",
            "[376]\teval-logloss:0.69315\n",
            "[377]\teval-logloss:0.69315\n",
            "[378]\teval-logloss:0.69315\n",
            "[379]\teval-logloss:0.69315\n",
            "[380]\teval-logloss:0.69315\n",
            "[381]\teval-logloss:0.69315\n",
            "[382]\teval-logloss:0.69315\n",
            "[383]\teval-logloss:0.69315\n",
            "[384]\teval-logloss:0.69315\n",
            "[385]\teval-logloss:0.69315\n",
            "[386]\teval-logloss:0.69315\n",
            "[387]\teval-logloss:0.69315\n",
            "[388]\teval-logloss:0.69315\n",
            "[389]\teval-logloss:0.69315\n",
            "[390]\teval-logloss:0.69315\n",
            "[391]\teval-logloss:0.69315\n",
            "[392]\teval-logloss:0.69315\n",
            "[393]\teval-logloss:0.69315\n",
            "[394]\teval-logloss:0.69315\n",
            "[395]\teval-logloss:0.69315\n",
            "[396]\teval-logloss:0.69315\n",
            "[397]\teval-logloss:0.69315\n",
            "[398]\teval-logloss:0.69315\n",
            "[399]\teval-logloss:0.69315\n",
            "[400]\teval-logloss:0.69315\n",
            "[401]\teval-logloss:0.69315\n",
            "[402]\teval-logloss:0.69315\n",
            "[403]\teval-logloss:0.69315\n",
            "[404]\teval-logloss:0.69315\n",
            "[405]\teval-logloss:0.69315\n",
            "[406]\teval-logloss:0.69315\n",
            "[407]\teval-logloss:0.69315\n",
            "[408]\teval-logloss:0.69315\n",
            "[409]\teval-logloss:0.69315\n",
            "[410]\teval-logloss:0.69315\n",
            "[411]\teval-logloss:0.69315\n",
            "[412]\teval-logloss:0.69315\n",
            "[413]\teval-logloss:0.69315\n",
            "[414]\teval-logloss:0.69315\n",
            "[415]\teval-logloss:0.69315\n",
            "[416]\teval-logloss:0.69315\n",
            "[417]\teval-logloss:0.69315\n",
            "[418]\teval-logloss:0.69315\n",
            "[419]\teval-logloss:0.69315\n",
            "[420]\teval-logloss:0.69315\n",
            "[421]\teval-logloss:0.69315\n",
            "[422]\teval-logloss:0.69315\n",
            "[423]\teval-logloss:0.69315\n",
            "[424]\teval-logloss:0.69315\n",
            "[425]\teval-logloss:0.69315\n",
            "[426]\teval-logloss:0.69315\n",
            "[427]\teval-logloss:0.69315\n",
            "[428]\teval-logloss:0.69315\n",
            "[429]\teval-logloss:0.69315\n",
            "[430]\teval-logloss:0.69315\n",
            "[431]\teval-logloss:0.69315\n",
            "[432]\teval-logloss:0.69315\n",
            "[433]\teval-logloss:0.69315\n",
            "[434]\teval-logloss:0.69315\n",
            "[435]\teval-logloss:0.69315\n",
            "[436]\teval-logloss:0.69315\n",
            "[437]\teval-logloss:0.69315\n",
            "[438]\teval-logloss:0.69315\n",
            "[439]\teval-logloss:0.69315\n",
            "[440]\teval-logloss:0.69315\n",
            "[441]\teval-logloss:0.69315\n",
            "[442]\teval-logloss:0.69315\n",
            "[443]\teval-logloss:0.69315\n",
            "[444]\teval-logloss:0.69315\n",
            "[445]\teval-logloss:0.69315\n",
            "[446]\teval-logloss:0.69315\n",
            "[447]\teval-logloss:0.69315\n",
            "[448]\teval-logloss:0.69315\n",
            "[449]\teval-logloss:0.69315\n",
            "[450]\teval-logloss:0.69315\n",
            "[451]\teval-logloss:0.69315\n",
            "[452]\teval-logloss:0.69315\n",
            "[453]\teval-logloss:0.69315\n",
            "[454]\teval-logloss:0.69315\n",
            "[455]\teval-logloss:0.69315\n",
            "[456]\teval-logloss:0.69315\n",
            "[457]\teval-logloss:0.69315\n",
            "[458]\teval-logloss:0.69315\n",
            "[459]\teval-logloss:0.69315\n",
            "[460]\teval-logloss:0.69315\n",
            "[461]\teval-logloss:0.69315\n",
            "[462]\teval-logloss:0.69315\n",
            "[463]\teval-logloss:0.69315\n",
            "[464]\teval-logloss:0.69315\n",
            "[465]\teval-logloss:0.69315\n",
            "[466]\teval-logloss:0.69315\n",
            "[467]\teval-logloss:0.69315\n",
            "[468]\teval-logloss:0.69315\n",
            "[469]\teval-logloss:0.69315\n",
            "[470]\teval-logloss:0.69315\n",
            "[471]\teval-logloss:0.69315\n",
            "[472]\teval-logloss:0.69315\n",
            "[473]\teval-logloss:0.69315\n",
            "[474]\teval-logloss:0.69315\n",
            "[475]\teval-logloss:0.69315\n",
            "[476]\teval-logloss:0.69315\n",
            "[477]\teval-logloss:0.69315\n",
            "[478]\teval-logloss:0.69315\n",
            "[479]\teval-logloss:0.69315\n",
            "[480]\teval-logloss:0.69315\n",
            "[481]\teval-logloss:0.69315\n",
            "[482]\teval-logloss:0.69315\n",
            "[483]\teval-logloss:0.69315\n",
            "[484]\teval-logloss:0.69315\n",
            "[485]\teval-logloss:0.69315\n",
            "[486]\teval-logloss:0.69315\n",
            "[487]\teval-logloss:0.69315\n",
            "[488]\teval-logloss:0.69315\n",
            "[489]\teval-logloss:0.69315\n",
            "[490]\teval-logloss:0.69315\n",
            "[491]\teval-logloss:0.69315\n",
            "[492]\teval-logloss:0.69315\n",
            "[493]\teval-logloss:0.69315\n",
            "[494]\teval-logloss:0.69315\n",
            "[495]\teval-logloss:0.69315\n",
            "[496]\teval-logloss:0.69315\n",
            "[497]\teval-logloss:0.69315\n",
            "[498]\teval-logloss:0.69315\n",
            "[499]\teval-logloss:0.69315\n",
            "[500]\teval-logloss:0.69315\n",
            "[501]\teval-logloss:0.69315\n",
            "[502]\teval-logloss:0.69315\n",
            "[503]\teval-logloss:0.69315\n",
            "[504]\teval-logloss:0.69315\n",
            "[505]\teval-logloss:0.69315\n",
            "[506]\teval-logloss:0.69315\n",
            "[507]\teval-logloss:0.69315\n",
            "[508]\teval-logloss:0.69315\n",
            "[509]\teval-logloss:0.69315\n",
            "[510]\teval-logloss:0.69315\n",
            "[511]\teval-logloss:0.69315\n",
            "[512]\teval-logloss:0.69315\n",
            "[513]\teval-logloss:0.69315\n",
            "[514]\teval-logloss:0.69315\n",
            "[515]\teval-logloss:0.69315\n",
            "[516]\teval-logloss:0.69315\n",
            "[517]\teval-logloss:0.69315\n",
            "[518]\teval-logloss:0.69315\n",
            "[519]\teval-logloss:0.69315\n",
            "[520]\teval-logloss:0.69315\n",
            "[521]\teval-logloss:0.69315\n",
            "[522]\teval-logloss:0.69315\n",
            "[523]\teval-logloss:0.69315\n",
            "[524]\teval-logloss:0.69315\n",
            "[525]\teval-logloss:0.69315\n",
            "[526]\teval-logloss:0.69315\n",
            "[527]\teval-logloss:0.69315\n",
            "[528]\teval-logloss:0.69315\n",
            "[529]\teval-logloss:0.69315\n",
            "[530]\teval-logloss:0.69315\n",
            "[531]\teval-logloss:0.69315\n",
            "[532]\teval-logloss:0.69315\n",
            "[533]\teval-logloss:0.69315\n",
            "[534]\teval-logloss:0.69315\n",
            "[535]\teval-logloss:0.69315\n",
            "[536]\teval-logloss:0.69315\n",
            "[537]\teval-logloss:0.69315\n",
            "[538]\teval-logloss:0.69315\n",
            "[539]\teval-logloss:0.69315\n",
            "[540]\teval-logloss:0.69315\n",
            "[541]\teval-logloss:0.69315\n",
            "[542]\teval-logloss:0.69315\n",
            "[543]\teval-logloss:0.69315\n",
            "[544]\teval-logloss:0.69315\n",
            "[545]\teval-logloss:0.69315\n",
            "[546]\teval-logloss:0.69315\n",
            "[547]\teval-logloss:0.69315\n",
            "[548]\teval-logloss:0.69315\n",
            "[549]\teval-logloss:0.69315\n",
            "[550]\teval-logloss:0.69315\n",
            "[551]\teval-logloss:0.69315\n",
            "[552]\teval-logloss:0.69315\n",
            "[553]\teval-logloss:0.69315\n",
            "[554]\teval-logloss:0.69315\n",
            "[555]\teval-logloss:0.69315\n",
            "[556]\teval-logloss:0.69315\n",
            "[557]\teval-logloss:0.69315\n",
            "[558]\teval-logloss:0.69315\n",
            "[559]\teval-logloss:0.69315\n",
            "[560]\teval-logloss:0.69315\n",
            "[561]\teval-logloss:0.69315\n",
            "[562]\teval-logloss:0.69315\n",
            "[563]\teval-logloss:0.69315\n",
            "[564]\teval-logloss:0.69315\n",
            "[565]\teval-logloss:0.69315\n",
            "[566]\teval-logloss:0.69315\n",
            "[567]\teval-logloss:0.69315\n",
            "[568]\teval-logloss:0.69315\n",
            "[569]\teval-logloss:0.69315\n",
            "[570]\teval-logloss:0.69315\n",
            "[571]\teval-logloss:0.69315\n",
            "[572]\teval-logloss:0.69315\n",
            "[573]\teval-logloss:0.69315\n",
            "[574]\teval-logloss:0.69315\n",
            "[575]\teval-logloss:0.69315\n",
            "[576]\teval-logloss:0.69315\n",
            "[577]\teval-logloss:0.69315\n",
            "[578]\teval-logloss:0.69315\n",
            "[579]\teval-logloss:0.69315\n",
            "[580]\teval-logloss:0.69315\n",
            "[581]\teval-logloss:0.69315\n",
            "[582]\teval-logloss:0.69315\n",
            "[583]\teval-logloss:0.69315\n",
            "[584]\teval-logloss:0.69315\n",
            "[585]\teval-logloss:0.69315\n",
            "[586]\teval-logloss:0.69315\n",
            "[587]\teval-logloss:0.69315\n",
            "[588]\teval-logloss:0.69315\n",
            "[589]\teval-logloss:0.69315\n",
            "[590]\teval-logloss:0.69315\n",
            "[591]\teval-logloss:0.69315\n",
            "[592]\teval-logloss:0.69315\n",
            "[593]\teval-logloss:0.69315\n",
            "[594]\teval-logloss:0.69315\n",
            "[595]\teval-logloss:0.69315\n",
            "[596]\teval-logloss:0.69315\n",
            "[597]\teval-logloss:0.69315\n",
            "[598]\teval-logloss:0.69315\n",
            "[599]\teval-logloss:0.69315\n",
            "[600]\teval-logloss:0.69315\n",
            "[601]\teval-logloss:0.69315\n",
            "[602]\teval-logloss:0.69315\n",
            "[603]\teval-logloss:0.69315\n",
            "[604]\teval-logloss:0.69315\n",
            "[605]\teval-logloss:0.69315\n",
            "[606]\teval-logloss:0.69315\n",
            "[607]\teval-logloss:0.69315\n",
            "[608]\teval-logloss:0.69315\n",
            "[609]\teval-logloss:0.69315\n",
            "[610]\teval-logloss:0.69315\n",
            "[611]\teval-logloss:0.69315\n",
            "[612]\teval-logloss:0.69315\n",
            "[613]\teval-logloss:0.69315\n",
            "[614]\teval-logloss:0.69315\n",
            "[615]\teval-logloss:0.69315\n",
            "[616]\teval-logloss:0.69315\n",
            "[617]\teval-logloss:0.69315\n",
            "[618]\teval-logloss:0.69315\n",
            "[619]\teval-logloss:0.69315\n",
            "[620]\teval-logloss:0.69315\n",
            "[621]\teval-logloss:0.69315\n",
            "[622]\teval-logloss:0.69315\n",
            "[623]\teval-logloss:0.69315\n",
            "[624]\teval-logloss:0.69315\n",
            "[625]\teval-logloss:0.69315\n",
            "[626]\teval-logloss:0.69315\n",
            "[627]\teval-logloss:0.69315\n",
            "[628]\teval-logloss:0.69315\n",
            "[629]\teval-logloss:0.69315\n",
            "[630]\teval-logloss:0.69315\n",
            "[631]\teval-logloss:0.69315\n",
            "[632]\teval-logloss:0.69315\n",
            "[633]\teval-logloss:0.69315\n",
            "[634]\teval-logloss:0.69315\n",
            "[635]\teval-logloss:0.69315\n",
            "[636]\teval-logloss:0.69315\n",
            "[637]\teval-logloss:0.69315\n",
            "[638]\teval-logloss:0.69315\n",
            "[639]\teval-logloss:0.69315\n",
            "[640]\teval-logloss:0.69315\n",
            "[641]\teval-logloss:0.69315\n",
            "[642]\teval-logloss:0.69315\n",
            "[643]\teval-logloss:0.69315\n",
            "[644]\teval-logloss:0.69315\n",
            "[645]\teval-logloss:0.69315\n",
            "[646]\teval-logloss:0.69315\n",
            "[647]\teval-logloss:0.69315\n",
            "[648]\teval-logloss:0.69315\n",
            "[649]\teval-logloss:0.69315\n",
            "[650]\teval-logloss:0.69315\n",
            "[651]\teval-logloss:0.69315\n",
            "[652]\teval-logloss:0.69315\n",
            "[653]\teval-logloss:0.69315\n",
            "[654]\teval-logloss:0.69315\n",
            "[655]\teval-logloss:0.69315\n",
            "[656]\teval-logloss:0.69315\n",
            "[657]\teval-logloss:0.69315\n",
            "[658]\teval-logloss:0.69315\n",
            "[659]\teval-logloss:0.69315\n",
            "[660]\teval-logloss:0.69315\n",
            "[661]\teval-logloss:0.69315\n",
            "[662]\teval-logloss:0.69315\n",
            "[663]\teval-logloss:0.69315\n",
            "[664]\teval-logloss:0.69315\n",
            "[665]\teval-logloss:0.69315\n",
            "[666]\teval-logloss:0.69315\n",
            "[667]\teval-logloss:0.69315\n",
            "[668]\teval-logloss:0.69315\n",
            "[669]\teval-logloss:0.69315\n",
            "[670]\teval-logloss:0.69315\n",
            "[671]\teval-logloss:0.69315\n",
            "[672]\teval-logloss:0.69315\n",
            "[673]\teval-logloss:0.69315\n",
            "[674]\teval-logloss:0.69315\n",
            "[675]\teval-logloss:0.69315\n",
            "[676]\teval-logloss:0.69315\n",
            "[677]\teval-logloss:0.69315\n",
            "[678]\teval-logloss:0.69315\n",
            "[679]\teval-logloss:0.69315\n",
            "[680]\teval-logloss:0.69315\n",
            "[681]\teval-logloss:0.69315\n",
            "[682]\teval-logloss:0.69315\n",
            "[683]\teval-logloss:0.69315\n",
            "[684]\teval-logloss:0.69315\n",
            "[685]\teval-logloss:0.69315\n",
            "[686]\teval-logloss:0.69315\n",
            "[687]\teval-logloss:0.69315\n",
            "[688]\teval-logloss:0.69315\n",
            "[689]\teval-logloss:0.69315\n",
            "[690]\teval-logloss:0.69315\n",
            "[691]\teval-logloss:0.69315\n",
            "[692]\teval-logloss:0.69315\n",
            "[693]\teval-logloss:0.69315\n",
            "[694]\teval-logloss:0.69315\n",
            "[695]\teval-logloss:0.69315\n",
            "[696]\teval-logloss:0.69315\n",
            "[697]\teval-logloss:0.69315\n",
            "[698]\teval-logloss:0.69315\n",
            "[699]\teval-logloss:0.69315\n",
            "[700]\teval-logloss:0.69315\n",
            "[701]\teval-logloss:0.69315\n",
            "[702]\teval-logloss:0.69315\n",
            "[703]\teval-logloss:0.69315\n",
            "[704]\teval-logloss:0.69315\n",
            "[705]\teval-logloss:0.69315\n",
            "[706]\teval-logloss:0.69315\n",
            "[707]\teval-logloss:0.69315\n",
            "[708]\teval-logloss:0.69315\n",
            "[709]\teval-logloss:0.69315\n",
            "[710]\teval-logloss:0.69315\n",
            "[711]\teval-logloss:0.69315\n",
            "[712]\teval-logloss:0.69315\n",
            "[713]\teval-logloss:0.69315\n",
            "[714]\teval-logloss:0.69315\n",
            "[715]\teval-logloss:0.69315\n",
            "[716]\teval-logloss:0.69315\n",
            "[717]\teval-logloss:0.69315\n",
            "[718]\teval-logloss:0.69315\n",
            "[719]\teval-logloss:0.69315\n",
            "[720]\teval-logloss:0.69315\n",
            "[721]\teval-logloss:0.69315\n",
            "[722]\teval-logloss:0.69315\n",
            "[723]\teval-logloss:0.69315\n",
            "[724]\teval-logloss:0.69315\n",
            "[725]\teval-logloss:0.69315\n",
            "[726]\teval-logloss:0.69315\n",
            "[727]\teval-logloss:0.69315\n",
            "[728]\teval-logloss:0.69315\n",
            "[729]\teval-logloss:0.69315\n",
            "[730]\teval-logloss:0.69315\n",
            "[731]\teval-logloss:0.69315\n",
            "[732]\teval-logloss:0.69315\n",
            "[733]\teval-logloss:0.69315\n",
            "[734]\teval-logloss:0.69315\n",
            "[735]\teval-logloss:0.69315\n",
            "[736]\teval-logloss:0.69315\n",
            "[737]\teval-logloss:0.69315\n",
            "[738]\teval-logloss:0.69315\n",
            "[739]\teval-logloss:0.69315\n",
            "[740]\teval-logloss:0.69315\n",
            "[741]\teval-logloss:0.69315\n",
            "[742]\teval-logloss:0.69315\n",
            "[743]\teval-logloss:0.69315\n",
            "[744]\teval-logloss:0.69315\n",
            "[745]\teval-logloss:0.69315\n",
            "[746]\teval-logloss:0.69315\n",
            "[747]\teval-logloss:0.69315\n",
            "[748]\teval-logloss:0.69315\n",
            "[749]\teval-logloss:0.69315\n",
            "[750]\teval-logloss:0.69315\n",
            "[751]\teval-logloss:0.69315\n",
            "[752]\teval-logloss:0.69315\n",
            "[753]\teval-logloss:0.69315\n",
            "[754]\teval-logloss:0.69315\n",
            "[755]\teval-logloss:0.69315\n",
            "[756]\teval-logloss:0.69315\n",
            "[757]\teval-logloss:0.69315\n",
            "[758]\teval-logloss:0.69315\n",
            "[759]\teval-logloss:0.69315\n",
            "[760]\teval-logloss:0.69315\n",
            "[761]\teval-logloss:0.69315\n",
            "[762]\teval-logloss:0.69315\n",
            "[763]\teval-logloss:0.69315\n",
            "[764]\teval-logloss:0.69315\n",
            "[765]\teval-logloss:0.69315\n",
            "[766]\teval-logloss:0.69315\n",
            "[767]\teval-logloss:0.69315\n",
            "[768]\teval-logloss:0.69315\n",
            "[769]\teval-logloss:0.69315\n",
            "[770]\teval-logloss:0.69315\n",
            "[771]\teval-logloss:0.69315\n",
            "[772]\teval-logloss:0.69315\n",
            "[773]\teval-logloss:0.69315\n",
            "[774]\teval-logloss:0.69315\n",
            "[775]\teval-logloss:0.69315\n",
            "[776]\teval-logloss:0.69315\n",
            "[777]\teval-logloss:0.69315\n",
            "[778]\teval-logloss:0.69315\n",
            "[779]\teval-logloss:0.69315\n",
            "[780]\teval-logloss:0.69315\n",
            "[781]\teval-logloss:0.69315\n",
            "[782]\teval-logloss:0.69315\n",
            "[783]\teval-logloss:0.69315\n",
            "[784]\teval-logloss:0.69315\n",
            "[785]\teval-logloss:0.69315\n",
            "[786]\teval-logloss:0.69315\n",
            "[787]\teval-logloss:0.69315\n",
            "[788]\teval-logloss:0.69315\n",
            "[789]\teval-logloss:0.69315\n",
            "[790]\teval-logloss:0.69315\n",
            "[791]\teval-logloss:0.69315\n",
            "[792]\teval-logloss:0.69315\n",
            "[793]\teval-logloss:0.69315\n",
            "[794]\teval-logloss:0.69315\n",
            "[795]\teval-logloss:0.69315\n",
            "[796]\teval-logloss:0.69315\n",
            "[797]\teval-logloss:0.69315\n",
            "[798]\teval-logloss:0.69315\n",
            "[799]\teval-logloss:0.69315\n",
            "[800]\teval-logloss:0.69315\n",
            "[801]\teval-logloss:0.69315\n",
            "[802]\teval-logloss:0.69315\n",
            "[803]\teval-logloss:0.69315\n",
            "[804]\teval-logloss:0.69315\n",
            "[805]\teval-logloss:0.69315\n",
            "[806]\teval-logloss:0.69315\n",
            "[807]\teval-logloss:0.69315\n",
            "[808]\teval-logloss:0.69315\n",
            "[809]\teval-logloss:0.69315\n",
            "[810]\teval-logloss:0.69315\n",
            "[811]\teval-logloss:0.69315\n",
            "[812]\teval-logloss:0.69315\n",
            "[813]\teval-logloss:0.69315\n",
            "[814]\teval-logloss:0.69315\n",
            "[815]\teval-logloss:0.69315\n",
            "[816]\teval-logloss:0.69315\n",
            "[817]\teval-logloss:0.69315\n",
            "[818]\teval-logloss:0.69315\n",
            "[819]\teval-logloss:0.69315\n",
            "[820]\teval-logloss:0.69315\n",
            "[821]\teval-logloss:0.69315\n",
            "[822]\teval-logloss:0.69315\n",
            "[823]\teval-logloss:0.69315\n",
            "[824]\teval-logloss:0.69315\n",
            "[825]\teval-logloss:0.69315\n",
            "[826]\teval-logloss:0.69315\n",
            "[827]\teval-logloss:0.69315\n",
            "[828]\teval-logloss:0.69315\n",
            "[829]\teval-logloss:0.69315\n",
            "[830]\teval-logloss:0.69315\n",
            "[831]\teval-logloss:0.69315\n",
            "[832]\teval-logloss:0.69315\n",
            "[833]\teval-logloss:0.69315\n",
            "[834]\teval-logloss:0.69315\n",
            "[835]\teval-logloss:0.69315\n",
            "[836]\teval-logloss:0.69315\n",
            "[837]\teval-logloss:0.69315\n",
            "[838]\teval-logloss:0.69315\n",
            "[839]\teval-logloss:0.69315\n",
            "[840]\teval-logloss:0.69315\n",
            "[841]\teval-logloss:0.69315\n",
            "[842]\teval-logloss:0.69315\n",
            "[843]\teval-logloss:0.69315\n",
            "[844]\teval-logloss:0.69315\n",
            "[845]\teval-logloss:0.69315\n",
            "[846]\teval-logloss:0.69315\n",
            "[847]\teval-logloss:0.69315\n",
            "[848]\teval-logloss:0.69315\n",
            "[849]\teval-logloss:0.69315\n",
            "[850]\teval-logloss:0.69315\n",
            "[851]\teval-logloss:0.69315\n",
            "[852]\teval-logloss:0.69315\n",
            "[853]\teval-logloss:0.69315\n",
            "[854]\teval-logloss:0.69315\n",
            "[855]\teval-logloss:0.69315\n",
            "[856]\teval-logloss:0.69315\n",
            "[857]\teval-logloss:0.69315\n",
            "[858]\teval-logloss:0.69315\n",
            "[859]\teval-logloss:0.69315\n",
            "[860]\teval-logloss:0.69315\n",
            "[861]\teval-logloss:0.69315\n",
            "[862]\teval-logloss:0.69315\n",
            "[863]\teval-logloss:0.69315\n",
            "[864]\teval-logloss:0.69315\n",
            "[865]\teval-logloss:0.69315\n",
            "[866]\teval-logloss:0.69315\n",
            "[867]\teval-logloss:0.69315\n",
            "[868]\teval-logloss:0.69315\n",
            "[869]\teval-logloss:0.69315\n",
            "[870]\teval-logloss:0.69315\n",
            "[871]\teval-logloss:0.69315\n",
            "[872]\teval-logloss:0.69315\n",
            "[873]\teval-logloss:0.69315\n",
            "[874]\teval-logloss:0.69315\n",
            "[875]\teval-logloss:0.69315\n",
            "[876]\teval-logloss:0.69315\n",
            "[877]\teval-logloss:0.69315\n",
            "[878]\teval-logloss:0.69315\n",
            "[879]\teval-logloss:0.69315\n",
            "[880]\teval-logloss:0.69315\n",
            "[881]\teval-logloss:0.69315\n",
            "[882]\teval-logloss:0.69315\n",
            "[883]\teval-logloss:0.69315\n",
            "[884]\teval-logloss:0.69315\n",
            "[885]\teval-logloss:0.69315\n",
            "[886]\teval-logloss:0.69315\n",
            "[887]\teval-logloss:0.69315\n",
            "[888]\teval-logloss:0.69315\n",
            "[889]\teval-logloss:0.69315\n",
            "[890]\teval-logloss:0.69315\n",
            "[891]\teval-logloss:0.69315\n",
            "[892]\teval-logloss:0.69315\n",
            "[893]\teval-logloss:0.69315\n",
            "[894]\teval-logloss:0.69315\n",
            "[895]\teval-logloss:0.69315\n",
            "[896]\teval-logloss:0.69315\n",
            "[897]\teval-logloss:0.69315\n",
            "[898]\teval-logloss:0.69315\n",
            "[899]\teval-logloss:0.69315\n",
            "[900]\teval-logloss:0.69315\n",
            "[901]\teval-logloss:0.69315\n",
            "[902]\teval-logloss:0.69315\n",
            "[903]\teval-logloss:0.69315\n",
            "[904]\teval-logloss:0.69315\n",
            "[905]\teval-logloss:0.69315\n",
            "[906]\teval-logloss:0.69315\n",
            "[907]\teval-logloss:0.69315\n",
            "[908]\teval-logloss:0.69315\n",
            "[909]\teval-logloss:0.69315\n",
            "[910]\teval-logloss:0.69315\n",
            "[911]\teval-logloss:0.69315\n",
            "[912]\teval-logloss:0.69315\n",
            "[913]\teval-logloss:0.69315\n",
            "[914]\teval-logloss:0.69315\n",
            "[915]\teval-logloss:0.69315\n",
            "[916]\teval-logloss:0.69315\n",
            "[917]\teval-logloss:0.69315\n",
            "[918]\teval-logloss:0.69315\n",
            "[919]\teval-logloss:0.69315\n",
            "[920]\teval-logloss:0.69315\n",
            "[921]\teval-logloss:0.69315\n",
            "[922]\teval-logloss:0.69315\n",
            "[923]\teval-logloss:0.69315\n",
            "[924]\teval-logloss:0.69315\n",
            "[925]\teval-logloss:0.69315\n",
            "[926]\teval-logloss:0.69315\n",
            "[927]\teval-logloss:0.69315\n",
            "[928]\teval-logloss:0.69315\n",
            "[929]\teval-logloss:0.69315\n",
            "[930]\teval-logloss:0.69315\n",
            "[931]\teval-logloss:0.69315\n",
            "[932]\teval-logloss:0.69315\n",
            "[933]\teval-logloss:0.69315\n",
            "[934]\teval-logloss:0.69315\n",
            "[935]\teval-logloss:0.69315\n",
            "[936]\teval-logloss:0.69315\n",
            "[937]\teval-logloss:0.69315\n",
            "[938]\teval-logloss:0.69315\n",
            "[939]\teval-logloss:0.69315\n",
            "[940]\teval-logloss:0.69315\n",
            "[941]\teval-logloss:0.69315\n",
            "[942]\teval-logloss:0.69315\n",
            "[943]\teval-logloss:0.69315\n",
            "[944]\teval-logloss:0.69315\n",
            "[945]\teval-logloss:0.69315\n",
            "[946]\teval-logloss:0.69315\n",
            "[947]\teval-logloss:0.69315\n",
            "[948]\teval-logloss:0.69315\n",
            "[949]\teval-logloss:0.69315\n",
            "[950]\teval-logloss:0.69315\n",
            "[951]\teval-logloss:0.69315\n",
            "[952]\teval-logloss:0.69315\n",
            "[953]\teval-logloss:0.69315\n",
            "[954]\teval-logloss:0.69315\n",
            "[955]\teval-logloss:0.69315\n",
            "[956]\teval-logloss:0.69315\n",
            "[957]\teval-logloss:0.69315\n",
            "[958]\teval-logloss:0.69315\n",
            "[959]\teval-logloss:0.69315\n",
            "[960]\teval-logloss:0.69315\n",
            "[961]\teval-logloss:0.69315\n",
            "[962]\teval-logloss:0.69315\n",
            "[963]\teval-logloss:0.69315\n",
            "[964]\teval-logloss:0.69315\n",
            "[965]\teval-logloss:0.69315\n",
            "[966]\teval-logloss:0.69315\n",
            "[967]\teval-logloss:0.69315\n",
            "[968]\teval-logloss:0.69315\n",
            "[969]\teval-logloss:0.69315\n",
            "[970]\teval-logloss:0.69315\n",
            "[971]\teval-logloss:0.69315\n",
            "[972]\teval-logloss:0.69315\n",
            "[973]\teval-logloss:0.69315\n",
            "[974]\teval-logloss:0.69315\n",
            "[975]\teval-logloss:0.69315\n",
            "[976]\teval-logloss:0.69315\n",
            "[977]\teval-logloss:0.69315\n",
            "[978]\teval-logloss:0.69315\n",
            "[979]\teval-logloss:0.69315\n",
            "[980]\teval-logloss:0.69315\n",
            "[981]\teval-logloss:0.69315\n",
            "[982]\teval-logloss:0.69315\n",
            "[983]\teval-logloss:0.69315\n",
            "[984]\teval-logloss:0.69315\n",
            "[985]\teval-logloss:0.69315\n",
            "[986]\teval-logloss:0.69315\n",
            "[987]\teval-logloss:0.69315\n",
            "[988]\teval-logloss:0.69315\n",
            "[989]\teval-logloss:0.69315\n",
            "[990]\teval-logloss:0.69315\n",
            "[991]\teval-logloss:0.69315\n",
            "[992]\teval-logloss:0.69315\n",
            "[993]\teval-logloss:0.69315\n",
            "[994]\teval-logloss:0.69315\n",
            "[995]\teval-logloss:0.69315\n",
            "[996]\teval-logloss:0.69315\n",
            "[997]\teval-logloss:0.69315\n",
            "[998]\teval-logloss:0.69315\n",
            "[999]\teval-logloss:0.69315\n",
            "[1000]\teval-logloss:0.69315\n",
            "[1001]\teval-logloss:0.69315\n",
            "[1002]\teval-logloss:0.69315\n",
            "[1003]\teval-logloss:0.69315\n",
            "[1004]\teval-logloss:0.69315\n",
            "[1005]\teval-logloss:0.69315\n",
            "[1006]\teval-logloss:0.69315\n",
            "[1007]\teval-logloss:0.69315\n",
            "[1008]\teval-logloss:0.69315\n",
            "[1009]\teval-logloss:0.69315\n",
            "[1010]\teval-logloss:0.69315\n",
            "[1011]\teval-logloss:0.69315\n",
            "[1012]\teval-logloss:0.69315\n",
            "[1013]\teval-logloss:0.69315\n",
            "[1014]\teval-logloss:0.69315\n",
            "[1015]\teval-logloss:0.69315\n",
            "[1016]\teval-logloss:0.69315\n",
            "[1017]\teval-logloss:0.69315\n",
            "[1018]\teval-logloss:0.69315\n",
            "[1019]\teval-logloss:0.69315\n",
            "[1020]\teval-logloss:0.69315\n",
            "[1021]\teval-logloss:0.69315\n",
            "[1022]\teval-logloss:0.69315\n",
            "[1023]\teval-logloss:0.69315\n",
            "[1024]\teval-logloss:0.69315\n",
            "[1025]\teval-logloss:0.69315\n",
            "[1026]\teval-logloss:0.69315\n",
            "[1027]\teval-logloss:0.69315\n",
            "[1028]\teval-logloss:0.69315\n",
            "[1029]\teval-logloss:0.69315\n",
            "[1030]\teval-logloss:0.69315\n",
            "[1031]\teval-logloss:0.69315\n",
            "[1032]\teval-logloss:0.69315\n",
            "[1033]\teval-logloss:0.69315\n",
            "[1034]\teval-logloss:0.69315\n",
            "[1035]\teval-logloss:0.69315\n",
            "[1036]\teval-logloss:0.69315\n",
            "[1037]\teval-logloss:0.69315\n",
            "[1038]\teval-logloss:0.69315\n",
            "[1039]\teval-logloss:0.69315\n",
            "[1040]\teval-logloss:0.69315\n",
            "[1041]\teval-logloss:0.69315\n",
            "[1042]\teval-logloss:0.69315\n",
            "[1043]\teval-logloss:0.69315\n",
            "[1044]\teval-logloss:0.69315\n",
            "[1045]\teval-logloss:0.69315\n",
            "[1046]\teval-logloss:0.69315\n",
            "[1047]\teval-logloss:0.69315\n",
            "[1048]\teval-logloss:0.69315\n",
            "[1049]\teval-logloss:0.69315\n",
            "[1050]\teval-logloss:0.69315\n",
            "[1051]\teval-logloss:0.69315\n",
            "[1052]\teval-logloss:0.69315\n",
            "[1053]\teval-logloss:0.69315\n",
            "[1054]\teval-logloss:0.69315\n",
            "[1055]\teval-logloss:0.69315\n",
            "[1056]\teval-logloss:0.69315\n",
            "[1057]\teval-logloss:0.69315\n",
            "[1058]\teval-logloss:0.69315\n",
            "[1059]\teval-logloss:0.69315\n",
            "[1060]\teval-logloss:0.69315\n",
            "[1061]\teval-logloss:0.69315\n",
            "[1062]\teval-logloss:0.69315\n",
            "[1063]\teval-logloss:0.69315\n",
            "[1064]\teval-logloss:0.69315\n",
            "[1065]\teval-logloss:0.69315\n",
            "[1066]\teval-logloss:0.69315\n",
            "[1067]\teval-logloss:0.69315\n",
            "[1068]\teval-logloss:0.69315\n",
            "[1069]\teval-logloss:0.69315\n",
            "[1070]\teval-logloss:0.69315\n",
            "[1071]\teval-logloss:0.69315\n",
            "[1072]\teval-logloss:0.69315\n",
            "[1073]\teval-logloss:0.69315\n",
            "[1074]\teval-logloss:0.69315\n",
            "[1075]\teval-logloss:0.69315\n",
            "[1076]\teval-logloss:0.69315\n",
            "[1077]\teval-logloss:0.69315\n",
            "[1078]\teval-logloss:0.69315\n",
            "[1079]\teval-logloss:0.69315\n",
            "[1080]\teval-logloss:0.69315\n",
            "[1081]\teval-logloss:0.69315\n",
            "[1082]\teval-logloss:0.69315\n",
            "[1083]\teval-logloss:0.69315\n",
            "[1084]\teval-logloss:0.69315\n",
            "[1085]\teval-logloss:0.69315\n",
            "[1086]\teval-logloss:0.69315\n",
            "[1087]\teval-logloss:0.69315\n",
            "[1088]\teval-logloss:0.69315\n",
            "[1089]\teval-logloss:0.69315\n",
            "[1090]\teval-logloss:0.69315\n",
            "[1091]\teval-logloss:0.69315\n",
            "[1092]\teval-logloss:0.69315\n",
            "[1093]\teval-logloss:0.69315\n",
            "[1094]\teval-logloss:0.69315\n",
            "[1095]\teval-logloss:0.69315\n",
            "[1096]\teval-logloss:0.69315\n",
            "[1097]\teval-logloss:0.69315\n",
            "[1098]\teval-logloss:0.69315\n",
            "[1099]\teval-logloss:0.69315\n",
            "[1100]\teval-logloss:0.69315\n",
            "[1101]\teval-logloss:0.69315\n",
            "[1102]\teval-logloss:0.69315\n",
            "[1103]\teval-logloss:0.69315\n",
            "[1104]\teval-logloss:0.69315\n",
            "[1105]\teval-logloss:0.69315\n",
            "[1106]\teval-logloss:0.69315\n",
            "[1107]\teval-logloss:0.69315\n",
            "[1108]\teval-logloss:0.69315\n",
            "[1109]\teval-logloss:0.69315\n",
            "[1110]\teval-logloss:0.69315\n",
            "[1111]\teval-logloss:0.69315\n",
            "[1112]\teval-logloss:0.69315\n",
            "[1113]\teval-logloss:0.69315\n",
            "[1114]\teval-logloss:0.69315\n",
            "[1115]\teval-logloss:0.69315\n",
            "[1116]\teval-logloss:0.69315\n",
            "[1117]\teval-logloss:0.69315\n",
            "[1118]\teval-logloss:0.69315\n",
            "[1119]\teval-logloss:0.69315\n",
            "[1120]\teval-logloss:0.69315\n",
            "[1121]\teval-logloss:0.69315\n",
            "[1122]\teval-logloss:0.69315\n",
            "[1123]\teval-logloss:0.69315\n",
            "[1124]\teval-logloss:0.69315\n",
            "[1125]\teval-logloss:0.69315\n",
            "[1126]\teval-logloss:0.69315\n",
            "[1127]\teval-logloss:0.69315\n",
            "[1128]\teval-logloss:0.69315\n",
            "[1129]\teval-logloss:0.69315\n",
            "[1130]\teval-logloss:0.69315\n",
            "[1131]\teval-logloss:0.69315\n",
            "[1132]\teval-logloss:0.69315\n",
            "[1133]\teval-logloss:0.69315\n",
            "[1134]\teval-logloss:0.69315\n",
            "[1135]\teval-logloss:0.69315\n",
            "[1136]\teval-logloss:0.69315\n",
            "[1137]\teval-logloss:0.69315\n",
            "[1138]\teval-logloss:0.69315\n",
            "[1139]\teval-logloss:0.69315\n",
            "[1140]\teval-logloss:0.69315\n",
            "[1141]\teval-logloss:0.69315\n",
            "[1142]\teval-logloss:0.69315\n",
            "[1143]\teval-logloss:0.69315\n",
            "[1144]\teval-logloss:0.69315\n",
            "[1145]\teval-logloss:0.69315\n",
            "[1146]\teval-logloss:0.69315\n",
            "[1147]\teval-logloss:0.69315\n",
            "[1148]\teval-logloss:0.69315\n",
            "[1149]\teval-logloss:0.69315\n",
            "[1150]\teval-logloss:0.69315\n",
            "[1151]\teval-logloss:0.69315\n",
            "[1152]\teval-logloss:0.69315\n",
            "[1153]\teval-logloss:0.69315\n",
            "[1154]\teval-logloss:0.69315\n",
            "[1155]\teval-logloss:0.69315\n",
            "[1156]\teval-logloss:0.69315\n",
            "[1157]\teval-logloss:0.69315\n",
            "[1158]\teval-logloss:0.69315\n",
            "[1159]\teval-logloss:0.69315\n",
            "[1160]\teval-logloss:0.69315\n",
            "[1161]\teval-logloss:0.69315\n",
            "[1162]\teval-logloss:0.69315\n",
            "[1163]\teval-logloss:0.69315\n",
            "[1164]\teval-logloss:0.69315\n",
            "[1165]\teval-logloss:0.69315\n",
            "[1166]\teval-logloss:0.69315\n",
            "[1167]\teval-logloss:0.69315\n",
            "[1168]\teval-logloss:0.69315\n",
            "[1169]\teval-logloss:0.69315\n",
            "[1170]\teval-logloss:0.69315\n",
            "[1171]\teval-logloss:0.69315\n",
            "[1172]\teval-logloss:0.69315\n",
            "[1173]\teval-logloss:0.69315\n",
            "[1174]\teval-logloss:0.69315\n",
            "[1175]\teval-logloss:0.69315\n",
            "[1176]\teval-logloss:0.69315\n",
            "[1177]\teval-logloss:0.69315\n",
            "[1178]\teval-logloss:0.69315\n",
            "[1179]\teval-logloss:0.69315\n",
            "[1180]\teval-logloss:0.69315\n",
            "[1181]\teval-logloss:0.69315\n",
            "[1182]\teval-logloss:0.69315\n",
            "[1183]\teval-logloss:0.69315\n",
            "[1184]\teval-logloss:0.69315\n",
            "[1185]\teval-logloss:0.69315\n",
            "[1186]\teval-logloss:0.69315\n",
            "[1187]\teval-logloss:0.69315\n",
            "[1188]\teval-logloss:0.69315\n",
            "[1189]\teval-logloss:0.69315\n",
            "[1190]\teval-logloss:0.69315\n",
            "[1191]\teval-logloss:0.69315\n",
            "[1192]\teval-logloss:0.69315\n",
            "[1193]\teval-logloss:0.69315\n",
            "[1194]\teval-logloss:0.69315\n",
            "[1195]\teval-logloss:0.69315\n",
            "[1196]\teval-logloss:0.69315\n",
            "[1197]\teval-logloss:0.69315\n",
            "[1198]\teval-logloss:0.69315\n",
            "[1199]\teval-logloss:0.69315\n",
            "[1200]\teval-logloss:0.69315\n",
            "[1201]\teval-logloss:0.69315\n",
            "[1202]\teval-logloss:0.69315\n",
            "[1203]\teval-logloss:0.69315\n",
            "[1204]\teval-logloss:0.69315\n",
            "[1205]\teval-logloss:0.69315\n",
            "[1206]\teval-logloss:0.69315\n",
            "[1207]\teval-logloss:0.69315\n",
            "[1208]\teval-logloss:0.69315\n",
            "[1209]\teval-logloss:0.69315\n",
            "[1210]\teval-logloss:0.69315\n",
            "[1211]\teval-logloss:0.69315\n",
            "[1212]\teval-logloss:0.69315\n",
            "[1213]\teval-logloss:0.69315\n",
            "[1214]\teval-logloss:0.69315\n",
            "[1215]\teval-logloss:0.69315\n",
            "[1216]\teval-logloss:0.69315\n",
            "[1217]\teval-logloss:0.69315\n",
            "[1218]\teval-logloss:0.69315\n",
            "[1219]\teval-logloss:0.69315\n",
            "[1220]\teval-logloss:0.69315\n",
            "[1221]\teval-logloss:0.69315\n",
            "[1222]\teval-logloss:0.69315\n",
            "[1223]\teval-logloss:0.69315\n",
            "[1224]\teval-logloss:0.69315\n",
            "[1225]\teval-logloss:0.69315\n",
            "[1226]\teval-logloss:0.69315\n",
            "[1227]\teval-logloss:0.69315\n",
            "[1228]\teval-logloss:0.69315\n",
            "[1229]\teval-logloss:0.69315\n",
            "[1230]\teval-logloss:0.69315\n",
            "[1231]\teval-logloss:0.69315\n",
            "[1232]\teval-logloss:0.69315\n",
            "[1233]\teval-logloss:0.69315\n",
            "[1234]\teval-logloss:0.69315\n",
            "[1235]\teval-logloss:0.69315\n",
            "[1236]\teval-logloss:0.69315\n",
            "[1237]\teval-logloss:0.69315\n",
            "[1238]\teval-logloss:0.69315\n",
            "[1239]\teval-logloss:0.69315\n",
            "[1240]\teval-logloss:0.69315\n",
            "[1241]\teval-logloss:0.69315\n",
            "[1242]\teval-logloss:0.69315\n",
            "[1243]\teval-logloss:0.69315\n",
            "[1244]\teval-logloss:0.69315\n",
            "[1245]\teval-logloss:0.69315\n",
            "[1246]\teval-logloss:0.69315\n",
            "[1247]\teval-logloss:0.69315\n",
            "[1248]\teval-logloss:0.69315\n",
            "[1249]\teval-logloss:0.69315\n",
            "[1250]\teval-logloss:0.69315\n",
            "[1251]\teval-logloss:0.69315\n",
            "[1252]\teval-logloss:0.69315\n",
            "[1253]\teval-logloss:0.69315\n",
            "[1254]\teval-logloss:0.69315\n",
            "[1255]\teval-logloss:0.69315\n",
            "[1256]\teval-logloss:0.69315\n",
            "[1257]\teval-logloss:0.69315\n",
            "[1258]\teval-logloss:0.69315\n",
            "[1259]\teval-logloss:0.69315\n",
            "[1260]\teval-logloss:0.69315\n",
            "[1261]\teval-logloss:0.69315\n",
            "[1262]\teval-logloss:0.69315\n",
            "[1263]\teval-logloss:0.69315\n",
            "[1264]\teval-logloss:0.69315\n",
            "[1265]\teval-logloss:0.69315\n",
            "[1266]\teval-logloss:0.69315\n",
            "[1267]\teval-logloss:0.69315\n",
            "[1268]\teval-logloss:0.69315\n",
            "[1269]\teval-logloss:0.69315\n",
            "[1270]\teval-logloss:0.69315\n",
            "[1271]\teval-logloss:0.69315\n",
            "[1272]\teval-logloss:0.69315\n",
            "[1273]\teval-logloss:0.69315\n",
            "[1274]\teval-logloss:0.69315\n",
            "[1275]\teval-logloss:0.69315\n",
            "[1276]\teval-logloss:0.69315\n",
            "[1277]\teval-logloss:0.69315\n",
            "[1278]\teval-logloss:0.69315\n",
            "[1279]\teval-logloss:0.69315\n",
            "[1280]\teval-logloss:0.69315\n",
            "[1281]\teval-logloss:0.69315\n",
            "[1282]\teval-logloss:0.69315\n",
            "[1283]\teval-logloss:0.69315\n",
            "[1284]\teval-logloss:0.69315\n",
            "[1285]\teval-logloss:0.69315\n",
            "[1286]\teval-logloss:0.69315\n",
            "[1287]\teval-logloss:0.69315\n",
            "[1288]\teval-logloss:0.69315\n",
            "[1289]\teval-logloss:0.69315\n",
            "[1290]\teval-logloss:0.69315\n",
            "[1291]\teval-logloss:0.69315\n",
            "[1292]\teval-logloss:0.69315\n",
            "[1293]\teval-logloss:0.69315\n",
            "[1294]\teval-logloss:0.69315\n",
            "[1295]\teval-logloss:0.69315\n",
            "[1296]\teval-logloss:0.69315\n",
            "[1297]\teval-logloss:0.69315\n",
            "[1298]\teval-logloss:0.69315\n",
            "[1299]\teval-logloss:0.69315\n",
            "[1300]\teval-logloss:0.69315\n",
            "[1301]\teval-logloss:0.69315\n",
            "[1302]\teval-logloss:0.69315\n",
            "[1303]\teval-logloss:0.69315\n",
            "[1304]\teval-logloss:0.69315\n",
            "[1305]\teval-logloss:0.69315\n",
            "[1306]\teval-logloss:0.69315\n",
            "[1307]\teval-logloss:0.69315\n",
            "[1308]\teval-logloss:0.69315\n",
            "[1309]\teval-logloss:0.69315\n",
            "[1310]\teval-logloss:0.69315\n",
            "[1311]\teval-logloss:0.69315\n",
            "[1312]\teval-logloss:0.69315\n",
            "[1313]\teval-logloss:0.69315\n",
            "[1314]\teval-logloss:0.69315\n",
            "[1315]\teval-logloss:0.69315\n",
            "[1316]\teval-logloss:0.69315\n",
            "[1317]\teval-logloss:0.69315\n",
            "[1318]\teval-logloss:0.69315\n",
            "[1319]\teval-logloss:0.69315\n",
            "[1320]\teval-logloss:0.69315\n",
            "[1321]\teval-logloss:0.69315\n",
            "[1322]\teval-logloss:0.69315\n",
            "[1323]\teval-logloss:0.69315\n",
            "[1324]\teval-logloss:0.69315\n",
            "[1325]\teval-logloss:0.69315\n",
            "[1326]\teval-logloss:0.69315\n",
            "[1327]\teval-logloss:0.69315\n",
            "[1328]\teval-logloss:0.69315\n",
            "[1329]\teval-logloss:0.69315\n",
            "[1330]\teval-logloss:0.69315\n",
            "[1331]\teval-logloss:0.69315\n",
            "[1332]\teval-logloss:0.69315\n",
            "[1333]\teval-logloss:0.69315\n",
            "[1334]\teval-logloss:0.69315\n",
            "[1335]\teval-logloss:0.69315\n",
            "[1336]\teval-logloss:0.69315\n",
            "[1337]\teval-logloss:0.69315\n",
            "[1338]\teval-logloss:0.69315\n",
            "[1339]\teval-logloss:0.69315\n",
            "[1340]\teval-logloss:0.69315\n",
            "[1341]\teval-logloss:0.69315\n",
            "[1342]\teval-logloss:0.69315\n",
            "[1343]\teval-logloss:0.69315\n",
            "[1344]\teval-logloss:0.69315\n",
            "[1345]\teval-logloss:0.69315\n",
            "[1346]\teval-logloss:0.69315\n",
            "[1347]\teval-logloss:0.69315\n",
            "[1348]\teval-logloss:0.69315\n",
            "[1349]\teval-logloss:0.69315\n",
            "[1350]\teval-logloss:0.69315\n",
            "[1351]\teval-logloss:0.69315\n",
            "[1352]\teval-logloss:0.69315\n",
            "[1353]\teval-logloss:0.69315\n",
            "[1354]\teval-logloss:0.69315\n",
            "[1355]\teval-logloss:0.69315\n",
            "[1356]\teval-logloss:0.69315\n",
            "[1357]\teval-logloss:0.69315\n",
            "[1358]\teval-logloss:0.69315\n",
            "[1359]\teval-logloss:0.69315\n",
            "[1360]\teval-logloss:0.69315\n",
            "[1361]\teval-logloss:0.69315\n",
            "[1362]\teval-logloss:0.69315\n",
            "[1363]\teval-logloss:0.69315\n",
            "[1364]\teval-logloss:0.69315\n",
            "[1365]\teval-logloss:0.69315\n",
            "[1366]\teval-logloss:0.69315\n",
            "[1367]\teval-logloss:0.69315\n",
            "[1368]\teval-logloss:0.69315\n",
            "[1369]\teval-logloss:0.69315\n",
            "[1370]\teval-logloss:0.69315\n",
            "[1371]\teval-logloss:0.69315\n",
            "[1372]\teval-logloss:0.69315\n",
            "[1373]\teval-logloss:0.69315\n",
            "[1374]\teval-logloss:0.69315\n",
            "[1375]\teval-logloss:0.69315\n",
            "[1376]\teval-logloss:0.69315\n",
            "[1377]\teval-logloss:0.69315\n",
            "[1378]\teval-logloss:0.69315\n",
            "[1379]\teval-logloss:0.69315\n",
            "[1380]\teval-logloss:0.69315\n",
            "[1381]\teval-logloss:0.69315\n",
            "[1382]\teval-logloss:0.69315\n",
            "[1383]\teval-logloss:0.69315\n",
            "[1384]\teval-logloss:0.69315\n",
            "[1385]\teval-logloss:0.69315\n",
            "[1386]\teval-logloss:0.69315\n",
            "[1387]\teval-logloss:0.69315\n",
            "[1388]\teval-logloss:0.69315\n",
            "[1389]\teval-logloss:0.69315\n",
            "[1390]\teval-logloss:0.69315\n",
            "[1391]\teval-logloss:0.69315\n",
            "[1392]\teval-logloss:0.69315\n",
            "[1393]\teval-logloss:0.69315\n",
            "[1394]\teval-logloss:0.69315\n",
            "[1395]\teval-logloss:0.69315\n",
            "[1396]\teval-logloss:0.69315\n",
            "[1397]\teval-logloss:0.69315\n",
            "[1398]\teval-logloss:0.69315\n",
            "[1399]\teval-logloss:0.69315\n",
            "[1400]\teval-logloss:0.69315\n",
            "[1401]\teval-logloss:0.69315\n",
            "[1402]\teval-logloss:0.69315\n",
            "[1403]\teval-logloss:0.69315\n",
            "[1404]\teval-logloss:0.69315\n",
            "[1405]\teval-logloss:0.69315\n",
            "[1406]\teval-logloss:0.69315\n",
            "[1407]\teval-logloss:0.69315\n",
            "[1408]\teval-logloss:0.69315\n",
            "[1409]\teval-logloss:0.69315\n",
            "[1410]\teval-logloss:0.69315\n",
            "[1411]\teval-logloss:0.69315\n",
            "[1412]\teval-logloss:0.69315\n",
            "[1413]\teval-logloss:0.69315\n",
            "[1414]\teval-logloss:0.69315\n",
            "[1415]\teval-logloss:0.69315\n",
            "[1416]\teval-logloss:0.69315\n",
            "[1417]\teval-logloss:0.69315\n",
            "[1418]\teval-logloss:0.69315\n",
            "[1419]\teval-logloss:0.69315\n",
            "[1420]\teval-logloss:0.69315\n",
            "[1421]\teval-logloss:0.69315\n",
            "[1422]\teval-logloss:0.69315\n",
            "[1423]\teval-logloss:0.69315\n",
            "[1424]\teval-logloss:0.69315\n",
            "[1425]\teval-logloss:0.69315\n",
            "[1426]\teval-logloss:0.69315\n",
            "[1427]\teval-logloss:0.69315\n",
            "[1428]\teval-logloss:0.69315\n",
            "[1429]\teval-logloss:0.69315\n",
            "[1430]\teval-logloss:0.69315\n",
            "[1431]\teval-logloss:0.69315\n",
            "[1432]\teval-logloss:0.69315\n",
            "[1433]\teval-logloss:0.69315\n",
            "[1434]\teval-logloss:0.69315\n",
            "[1435]\teval-logloss:0.69315\n",
            "[1436]\teval-logloss:0.69315\n",
            "[1437]\teval-logloss:0.69315\n",
            "[1438]\teval-logloss:0.69315\n",
            "[1439]\teval-logloss:0.69315\n",
            "[1440]\teval-logloss:0.69315\n",
            "[1441]\teval-logloss:0.69315\n",
            "[1442]\teval-logloss:0.69315\n",
            "[1443]\teval-logloss:0.69315\n",
            "[1444]\teval-logloss:0.69315\n",
            "[1445]\teval-logloss:0.69315\n",
            "[1446]\teval-logloss:0.69315\n",
            "[1447]\teval-logloss:0.69315\n",
            "[1448]\teval-logloss:0.69315\n",
            "[1449]\teval-logloss:0.69315\n",
            "[1450]\teval-logloss:0.69315\n",
            "[1451]\teval-logloss:0.69315\n",
            "[1452]\teval-logloss:0.69315\n",
            "[1453]\teval-logloss:0.69315\n",
            "[1454]\teval-logloss:0.69315\n",
            "[1455]\teval-logloss:0.69315\n",
            "[1456]\teval-logloss:0.69315\n",
            "[1457]\teval-logloss:0.69315\n",
            "[1458]\teval-logloss:0.69315\n",
            "[1459]\teval-logloss:0.69315\n",
            "[1460]\teval-logloss:0.69315\n",
            "[1461]\teval-logloss:0.69315\n",
            "Validation Accuracy: 0.1613958560523446\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      1.00      0.28       148\n",
            "           1       0.00      0.00      0.00       769\n",
            "\n",
            "    accuracy                           0.16       917\n",
            "   macro avg       0.08      0.50      0.14       917\n",
            "weighted avg       0.03      0.16      0.04       917\n",
            "\n",
            "Predictions saved to submission_xgb_focal_smote_dmatrix.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This leads to all predictions swaying towards label 0."
      ],
      "metadata": {
        "id": "J9wA_6pZIeGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('target_encode', TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train, y_train)\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Calculate class weights\n",
        "class_0_weight = 1  # Adjust as needed\n",
        "class_1_weight = (y_train_balanced.value_counts()[0] / y_train_balanced.value_counts()[1])\n",
        "\n",
        "# Define the model parameters\n",
        "params = {\n",
        "    'n_estimators': 1462,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.008252647239585268,\n",
        "    'subsample': 0.8798353150886109,\n",
        "    'colsample_bytree': 0.9915078582609945,\n",
        "    'reg_lambda': 0.0021412922470020242,\n",
        "    'alpha': 1.1851271361097405e-05,\n",
        "    'scale_pos_weight': class_1_weight,  # Adjusted for class imbalance\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'mlogloss'\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = xgb.XGBClassifier(**params)\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Validate the model\n",
        "y_pred = model.predict(X_valid_transformed)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Prepare test data for prediction\n",
        "test_data_transformed = preprocessor.transform(test_data)\n",
        "test_predictions = model.predict(test_data_transformed)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission_df.to_csv('submission_xgb_smote.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_xgb_smote.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HctpUjQgLCu",
        "outputId": "def47e2c-5f78-40ed-fea5-5ab0ecaf0a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8669574700109052\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.37      0.47       148\n",
            "           1       0.89      0.96      0.92       769\n",
            "\n",
            "    accuracy                           0.87       917\n",
            "   macro avg       0.77      0.67      0.70       917\n",
            "weighted avg       0.85      0.87      0.85       917\n",
            "\n",
            "Predictions saved to submission_xgb_smote.csv\n",
            "Validation Accuracy (Adjusted): 0.8549618320610687\n",
            "Classification Report (Adjusted):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.19      0.30       148\n",
            "           1       0.86      0.98      0.92       769\n",
            "\n",
            "    accuracy                           0.85       917\n",
            "   macro avg       0.77      0.59      0.61       917\n",
            "weighted avg       0.83      0.85      0.82       917\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['output'])\n",
        "y = train_data['output']\n",
        "\n",
        "# Ensure categorical columns are of type 'category'\n",
        "categorical_columns = ['subject', 'phase', 'state']\n",
        "for col in categorical_columns:\n",
        "    X[col] = X[col].astype('category')\n",
        "\n",
        "# Split data for validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define numeric columns\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('target_encode', TargetEncoder(cols=categorical_columns), categorical_columns),\n",
        "    ('scaler', StandardScaler(), numeric_columns)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "X_train_transformed = preprocessor.fit_transform(X_train, y_train)\n",
        "X_valid_transformed = preprocessor.transform(X_valid)\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
        "\n",
        "# Calculate class weights\n",
        "class_0_weight = 1  # Adjust as needed\n",
        "class_1_weight = (y_train_balanced.value_counts()[0] / y_train_balanced.value_counts()[1])\n",
        "\n",
        "# Define the model parameters\n",
        "params = {\n",
        "    'n_estimators': 1462,\n",
        "    'max_depth': 6,\n",
        "    'learning_rate': 0.008252647239585268,\n",
        "    'subsample': 0.8798353150886109,\n",
        "    'colsample_bytree': 0.9915078582609945,\n",
        "    'reg_lambda': 0.0021412922470020242,\n",
        "    'alpha': 1.1851271361097405e-05,\n",
        "    'scale_pos_weight': class_1_weight,  # Adjusted for class imbalance\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'mlogloss'\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = xgb.XGBClassifier(**params)\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Validate the model\n",
        "y_pred = model.predict(X_valid_transformed)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Prepare test data for prediction\n",
        "test_data[categorical_columns] = test_data[categorical_columns].astype('category')  # Ensure correct types\n",
        "test_data_transformed = preprocessor.transform(test_data)\n",
        "test_predictions = model.predict(test_data_transformed)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission_df.to_csv('submission_xgb_smote.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to submission_xgb_smote.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC9fz8Abh2hr",
        "outputId": "f4248350-513f-4a38-c1b8-0316b6584f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8680479825517994\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.36      0.47       148\n",
            "           1       0.89      0.96      0.92       769\n",
            "\n",
            "    accuracy                           0.87       917\n",
            "   macro avg       0.78      0.66      0.70       917\n",
            "weighted avg       0.85      0.87      0.85       917\n",
            "\n",
            "Predictions saved to submission_xgb_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Display the first few rows of the training data to verify\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Identify feature columns and target column\n",
        "feature_columns = [f'x{i}' for i in range(1, 221)]  # Feature columns x1 to x220\n",
        "target_column = 'output'  # The target column\n",
        "\n",
        "# Split the training data into features and target\n",
        "X = train_data[feature_columns].values\n",
        "y = train_data[target_column].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(64, 32)           # Second hidden layer\n",
        "        self.fc3 = nn.Linear(32, num_classes)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))            # Activation function\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create the model\n",
        "input_size = X_train.shape[1]\n",
        "num_classes = len(np.unique(y))  # Assuming y contains class labels\n",
        "model = SimpleNN(input_size, num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Validation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_outputs = model(X_val_tensor)\n",
        "    _, val_predictions = torch.max(val_outputs, 1)\n",
        "    val_accuracy = accuracy_score(y_val, val_predictions.numpy())\n",
        "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "# Test set evaluation\n",
        "X_test = test_data[feature_columns].values\n",
        "X_test_scaled = scaler.transform(X_test)  # Standardize test data\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, test_predictions = torch.max(test_outputs, 1)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,  # Using the index of the test data for the 'id' column\n",
        "    'output': test_predictions.numpy()  # Predictions should be converted to a numpy array\n",
        "})\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Predictions saved to 'submission.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R9uGc5EnDTB",
        "outputId": "c2edea7f-ff3e-40ee-88c5-3749d27d0b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "   x1  x2  x3  x4          x5        x6        x7          x8        x9  \\\n",
            "0   0   0   0   1 -323.106605  2.694366 -1.987520  261.092784  0.013704   \n",
            "1   0   0   0   1 -376.084691  0.969696 -6.933765  355.311648  0.030292   \n",
            "2   0   0   0   0   91.955425  2.621643 -2.581162   51.357206  0.036668   \n",
            "3   0   0   0   1 -391.814586  1.866914 -2.510799  382.900317  0.007947   \n",
            "4   0   0   0   0 -363.823732  2.951346 -3.726368  330.527539  0.010074   \n",
            "\n",
            "        x10  ...      z217      z218      z219       z220       z221  \\\n",
            "0  0.000100  ... -0.004930 -0.005554  5.246375  -7.534092   3.530736   \n",
            "1 -0.000153  ...  0.022757  0.052506 -3.727741  -2.854443  -0.699268   \n",
            "2 -0.000104  ... -0.086813 -0.101497 -7.510594  19.564182 -17.008130   \n",
            "3 -0.000028  ...  0.030856 -0.161398 -6.435819   2.174453  -0.153956   \n",
            "4 -0.000004  ... -0.017226 -0.016454 -2.581403   3.011932  -1.281361   \n",
            "\n",
            "       z222  subject  phase  state  output  \n",
            "0 -0.539045        K      3      C       1  \n",
            "1 -0.054074        A      4      C       1  \n",
            "2  4.945392        D      3      C       1  \n",
            "3 -0.003958        G      2      C       0  \n",
            "4  0.192647        C      2      C       1  \n",
            "\n",
            "[5 rows x 670 columns]\n",
            "\n",
            "Test Data:\n",
            "   x1  x2  x3  x4          x5        x6         x7          x8        x9  \\\n",
            "0   0   0   0   1    4.665949  0.083412 -17.397081    0.067865  0.005895   \n",
            "1   0   0   0   0 -398.299487  0.784032 -10.785768  403.784446  0.070405   \n",
            "2   0   0   0   1 -380.902140  0.671324  -9.265829  361.841929  0.006937   \n",
            "3   0   0   0   1 -342.784124  0.469414  -8.044287  293.043601  0.007217   \n",
            "4   0   0   0   1    6.248502  0.252336  -5.398056    0.110097  0.005573   \n",
            "\n",
            "        x10  ...      z216      z217      z218        z219         z220  \\\n",
            "0  0.000012  ... -0.017574 -0.004402  0.016508 -540.645279 -1511.001159   \n",
            "1  0.000180  ...  0.029533  0.113692  0.088024   -3.140961    -0.658456   \n",
            "2  0.000025  ... -0.006361  0.005852 -0.003745  -14.340790     4.182214   \n",
            "3 -0.000021  ...  0.001950 -0.003426 -0.011191  251.659680  -441.129598   \n",
            "4  0.000010  ... -0.001916 -0.015666 -0.015960 -137.847658  -377.758402   \n",
            "\n",
            "          z221        z222  subject  phase  state  \n",
            "0 -1408.385976 -437.807290        E      4      D  \n",
            "1    -0.140010   -0.011017        H      4      D  \n",
            "2    -0.549953    0.019553        C      4      B  \n",
            "3   256.986592  -49.745359        H      1      C  \n",
            "4  -345.673251 -105.633150        E      4      B  \n",
            "\n",
            "[5 rows x 669 columns]\n",
            "Epoch [10/100], Loss: 0.5108\n",
            "Epoch [20/100], Loss: 0.4439\n",
            "Epoch [30/100], Loss: 0.4312\n",
            "Epoch [40/100], Loss: 0.4181\n",
            "Epoch [50/100], Loss: 0.4096\n",
            "Epoch [60/100], Loss: 0.4025\n",
            "Epoch [70/100], Loss: 0.3957\n",
            "Epoch [80/100], Loss: 0.3895\n",
            "Epoch [90/100], Loss: 0.3833\n",
            "Epoch [100/100], Loss: 0.3773\n",
            "Validation Accuracy: 0.8386\n",
            "Predictions saved to 'submission.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the datasets\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Define feature and target columns\n",
        "feature_columns = train_data.columns[:-4]  # Assuming the last 4 columns are non-feature columns\n",
        "target_column = 'output'  # Replace with your actual target column name\n",
        "\n",
        "# Split the training data into features and target\n",
        "X = train_data[feature_columns].values\n",
        "y = train_data[target_column].values\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can tweak the number of estimators\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "val_predictions = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
        "\n",
        "# Prepare the test data\n",
        "X_test = test_data[feature_columns].values\n",
        "X_test_scaled = scaler.transform(X_test)  # Scale test data using the same scaler\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Save predictions for submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data.index,  # Use the appropriate ID column if available\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission_df.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14f8mD59o3o1",
        "outputId": "19cf8407-c2d7-41f2-d8ac-0229e80c45c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out Tpot as automl to find best pipeline"
      ],
      "metadata": {
        "id": "SwfjzPYdIyev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tpot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATC6e8optCr_",
        "outputId": "d6e8146e-b219-47a6-d1f8-0aa75fd1e9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tpot\n",
            "  Downloading TPOT-0.12.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.5.2)\n",
            "Collecting deap>=1.2 (from tpot)\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting update-checker>=0.16 (from tpot)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (4.66.5)\n",
            "Collecting stopit>=1.1.1 (from tpot)\n",
            "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tpot) (2.2.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.4.2)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tpot) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.1->tpot) (3.5.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost>=1.1.0->tpot) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2024.8.30)\n",
            "Downloading TPOT-0.12.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11939 sha256=9e22fa339d4cc95dfa6bc334f6d018508be5631080a48fc71dd1307921300971\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/f9/87/bf5b3d565c2a007b4dae9d8142dccc85a9f164e517062dd519\n",
            "Successfully built stopit\n",
            "Installing collected packages: stopit, deap, update-checker, tpot\n",
            "Successfully installed deap-1.4.1 stopit-1.1.2 tpot-0.12.2 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tpot import TPOTClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your training data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Check if there are any non-numeric columns\n",
        "def encode_categorical(df):\n",
        "    label_encoders = {}\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df[column] = le.fit_transform(df[column])\n",
        "            label_encoders[column] = le  # Store the encoder for later use if needed\n",
        "    return df, label_encoders\n",
        "\n",
        "# Assuming the 'output' column is your target column and the rest are features\n",
        "X_train = train_data.drop(columns=['output'])  # Drop target column\n",
        "y_train = train_data['output']\n",
        "\n",
        "# Encode non-numeric columns in X_train and test_data\n",
        "X_train, train_encoders = encode_categorical(X_train)\n",
        "test_data, _ = encode_categorical(test_data)\n",
        "\n",
        "# Split the training data into train/validation sets for TPOT optimization\n",
        "X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up TPOT for AutoML (you can adjust the parameters as needed)\n",
        "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
        "\n",
        "# Train AutoML to find the best classifier\n",
        "tpot.fit(X_train_part, y_train_part)\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "print(\"Validation Score: \", tpot.score(X_val_part, y_val_part))\n",
        "\n",
        "# After optimization, predict on the test set\n",
        "# X_test = test_data.drop(columns=['id'])  # Assuming 'id' is not used for prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602,
          "referenced_widgets": [
            "fec24a3993df438ba67906e531bb7832",
            "67390c0f0191498cb472effe45608186",
            "5eae86f0e22f4e23a1f722e5940760cc",
            "a2158c50708244ba8fb14b8b872572bc",
            "b1c68c550bfa47b2846b4b1e9e796b3e",
            "5b3d25e708d840ae9a5381dd0390b61b",
            "69525a34deb94341a1afa50ee939716a",
            "1008adabde8d4e0ba6816c5194f681b4",
            "e1d928ab6d124c1b98988fce8d4d3bce",
            "39379970d2fa45748443cd01e1bb38e4",
            "adc0ea92bd1644dd8ee317b86a28c0df"
          ]
        },
        "id": "xdxTjPCEtGYD",
        "outputId": "a84886db-cf90-4da5-c1e4-5d959fcf3263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fec24a3993df438ba67906e531bb7832"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generation 1 - Current best internal CV score: 0.8658303935526799\n",
            "\n",
            "Generation 2 - Current best internal CV score: 0.8658303935526799\n",
            "\n",
            "Generation 3 - Current best internal CV score: 0.8677399808929745\n",
            "\n",
            "Generation 4 - Current best internal CV score: 0.869922419529313\n",
            "\n",
            "Generation 5 - Current best internal CV score: 0.869922419529313\n",
            "\n",
            "Best pipeline: ExtraTreesClassifier(CombineDFs(input_matrix, input_matrix), bootstrap=False, criterion=entropy, max_features=0.6500000000000001, min_samples_leaf=11, min_samples_split=2, n_estimators=100)\n",
            "Validation Score:  0.8767720828789531\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['id'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-eec1a81d66fe>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# After optimization, predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming 'id' is not used for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['id'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_data\n",
        "test_predictions = tpot.predict(X_test)"
      ],
      "metadata": {
        "id": "2DwHVQqVeHBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the predictions to 'submission.csv' file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data.index,  # Assuming there's an 'id' column in test_data\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Export the best model pipeline\n",
        "tpot.export('best_pipeline.py')\n",
        "print(\"Best model pipeline exported to 'best_pipeline.py'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr1zJGF0fjQB",
        "outputId": "5c8b737f-95a7-4ad4-a892-e2eb3fc5104b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model pipeline exported to 'best_pipeline.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tpot.export_utils import set_param_recursive\n",
        "\n",
        "# Load your training and test data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "test_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "# Encode categorical variables\n",
        "def encode_categorical(df):\n",
        "    label_encoders = {}\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df[column] = le.fit_transform(df[column])\n",
        "            label_encoders[column] = le\n",
        "    return df, label_encoders\n",
        "\n",
        "X_train = train_data.drop(columns=['output'])\n",
        "y_train = train_data['output']\n",
        "\n",
        "X_train, train_encoders = encode_categorical(X_train)\n",
        "test_data, _ = encode_categorical(test_data)\n",
        "\n",
        "# Check the actual columns in the dataset\n",
        "print(\"Training feature columns:\", X_train.columns.tolist())\n",
        "\n",
        "# Example of creating interaction features\n",
        "# Let's say we want to create interaction features for the first two numerical columns\n",
        "numerical_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if len(numerical_features) >= 2:\n",
        "    X_train['interaction'] = X_train[numerical_features[0]] * X_train[numerical_features[1]]\n",
        "    test_data['interaction'] = test_data[numerical_features[0]] * test_data[numerical_features[1]]\n",
        "\n",
        "# Example of polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "test_data_poly = poly.transform(test_data)\n",
        "\n",
        "# Splitting the data\n",
        "X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(X_train_poly, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the pipeline\n",
        "best_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    PCA(n_components=50),\n",
        "    ExtraTreesClassifier(\n",
        "        bootstrap=False,\n",
        "        criterion=\"entropy\",\n",
        "        max_features=0.65,\n",
        "        min_samples_leaf=11,\n",
        "        min_samples_split=2,\n",
        "        n_estimators=100,\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "best_pipeline.fit(X_train_part, y_train_part)\n",
        "\n",
        "# Evaluate the model\n",
        "val_score = best_pipeline.score(X_val_part, y_val_part)\n",
        "print(\"Validation Score: \", val_score)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = best_pipeline.predict(test_data_poly)\n",
        "\n",
        "# Prepare the submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_data.index,\n",
        "    'output': test_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvPPn4b0h_Oi",
        "outputId": "84ae179b-849b-43f5-fdab-cfd4fb23cf25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training feature columns: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64', 'x65', 'x66', 'x67', 'x68', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84', 'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x93', 'x94', 'x95', 'x96', 'x97', 'x98', 'x99', 'x100', 'x101', 'x102', 'x103', 'x104', 'x105', 'x106', 'x107', 'x108', 'x109', 'x110', 'x111', 'x112', 'x113', 'x114', 'x115', 'x116', 'x117', 'x118', 'x119', 'x120', 'x121', 'x122', 'x123', 'x124', 'x125', 'x126', 'x127', 'x128', 'x129', 'x130', 'x131', 'x132', 'x133', 'x134', 'x135', 'x136', 'x137', 'x138', 'x139', 'x140', 'x141', 'x142', 'x143', 'x144', 'x145', 'x146', 'x147', 'x148', 'x149', 'x150', 'x151', 'x152', 'x153', 'x154', 'x155', 'x156', 'x157', 'x158', 'x159', 'x160', 'x161', 'x162', 'x163', 'x164', 'x165', 'x166', 'x167', 'x168', 'x169', 'x170', 'x171', 'x172', 'x173', 'x174', 'x175', 'x176', 'x177', 'x178', 'x179', 'x180', 'x181', 'x182', 'x183', 'x184', 'x185', 'x186', 'x187', 'x188', 'x189', 'x190', 'x191', 'x192', 'x193', 'x194', 'x195', 'x196', 'x197', 'x198', 'x199', 'x200', 'x201', 'x202', 'x203', 'x204', 'x205', 'x206', 'x207', 'x208', 'x209', 'x210', 'x211', 'x212', 'x213', 'x214', 'x215', 'x216', 'x217', 'x218', 'x219', 'x220', 'x221', 'x222', 'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9', 'y10', 'y11', 'y12', 'y13', 'y14', 'y15', 'y16', 'y17', 'y18', 'y19', 'y20', 'y21', 'y22', 'y23', 'y24', 'y25', 'y26', 'y27', 'y28', 'y29', 'y30', 'y31', 'y32', 'y33', 'y34', 'y35', 'y36', 'y37', 'y38', 'y39', 'y40', 'y41', 'y42', 'y43', 'y44', 'y45', 'y46', 'y47', 'y48', 'y49', 'y50', 'y51', 'y52', 'y53', 'y54', 'y55', 'y56', 'y57', 'y58', 'y59', 'y60', 'y61', 'y62', 'y63', 'y64', 'y65', 'y66', 'y67', 'y68', 'y69', 'y70', 'y71', 'y72', 'y73', 'y74', 'y75', 'y76', 'y77', 'y78', 'y79', 'y80', 'y81', 'y82', 'y83', 'y84', 'y85', 'y86', 'y87', 'y88', 'y89', 'y90', 'y91', 'y92', 'y93', 'y94', 'y95', 'y96', 'y97', 'y98', 'y99', 'y100', 'y101', 'y102', 'y103', 'y104', 'y105', 'y106', 'y107', 'y108', 'y109', 'y110', 'y111', 'y112', 'y113', 'y114', 'y115', 'y116', 'y117', 'y118', 'y119', 'y120', 'y121', 'y122', 'y123', 'y124', 'y125', 'y126', 'y127', 'y128', 'y129', 'y130', 'y131', 'y132', 'y133', 'y134', 'y135', 'y136', 'y137', 'y138', 'y139', 'y140', 'y141', 'y142', 'y143', 'y144', 'y145', 'y146', 'y147', 'y148', 'y149', 'y150', 'y151', 'y152', 'y153', 'y154', 'y155', 'y156', 'y157', 'y158', 'y159', 'y160', 'y161', 'y162', 'y163', 'y164', 'y165', 'y166', 'y167', 'y168', 'y169', 'y170', 'y171', 'y172', 'y173', 'y174', 'y175', 'y176', 'y177', 'y178', 'y179', 'y180', 'y181', 'y182', 'y183', 'y184', 'y185', 'y186', 'y187', 'y188', 'y189', 'y190', 'y191', 'y192', 'y193', 'y194', 'y195', 'y196', 'y197', 'y198', 'y199', 'y200', 'y201', 'y202', 'y203', 'y204', 'y205', 'y206', 'y207', 'y208', 'y209', 'y210', 'y211', 'y212', 'y213', 'y214', 'y215', 'y216', 'y217', 'y218', 'y219', 'y220', 'y221', 'y222', 'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9', 'z10', 'z11', 'z12', 'z13', 'z14', 'z15', 'z16', 'z17', 'z18', 'z19', 'z20', 'z21', 'z22', 'z23', 'z24', 'z25', 'z26', 'z27', 'z28', 'z29', 'z30', 'z31', 'z32', 'z33', 'z34', 'z35', 'z36', 'z37', 'z38', 'z39', 'z40', 'z41', 'z42', 'z43', 'z44', 'z45', 'z46', 'z47', 'z48', 'z49', 'z50', 'z51', 'z52', 'z53', 'z54', 'z55', 'z56', 'z57', 'z58', 'z59', 'z60', 'z61', 'z62', 'z63', 'z64', 'z65', 'z66', 'z67', 'z68', 'z69', 'z70', 'z71', 'z72', 'z73', 'z74', 'z75', 'z76', 'z77', 'z78', 'z79', 'z80', 'z81', 'z82', 'z83', 'z84', 'z85', 'z86', 'z87', 'z88', 'z89', 'z90', 'z91', 'z92', 'z93', 'z94', 'z95', 'z96', 'z97', 'z98', 'z99', 'z100', 'z101', 'z102', 'z103', 'z104', 'z105', 'z106', 'z107', 'z108', 'z109', 'z110', 'z111', 'z112', 'z113', 'z114', 'z115', 'z116', 'z117', 'z118', 'z119', 'z120', 'z121', 'z122', 'z123', 'z124', 'z125', 'z126', 'z127', 'z128', 'z129', 'z130', 'z131', 'z132', 'z133', 'z134', 'z135', 'z136', 'z137', 'z138', 'z139', 'z140', 'z141', 'z142', 'z143', 'z144', 'z145', 'z146', 'z147', 'z148', 'z149', 'z150', 'z151', 'z152', 'z153', 'z154', 'z155', 'z156', 'z157', 'z158', 'z159', 'z160', 'z161', 'z162', 'z163', 'z164', 'z165', 'z166', 'z167', 'z168', 'z169', 'z170', 'z171', 'z172', 'z173', 'z174', 'z175', 'z176', 'z177', 'z178', 'z179', 'z180', 'z181', 'z182', 'z183', 'z184', 'z185', 'z186', 'z187', 'z188', 'z189', 'z190', 'z191', 'z192', 'z193', 'z194', 'z195', 'z196', 'z197', 'z198', 'z199', 'z200', 'z201', 'z202', 'z203', 'z204', 'z205', 'z206', 'z207', 'z208', 'z209', 'z210', 'z211', 'z212', 'z213', 'z214', 'z215', 'z216', 'z217', 'z218', 'z219', 'z220', 'z221', 'z222', 'subject', 'phase', 'state']\n",
            "Validation Score:  0.8440567066521265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not improve test accuracy even though TPOT runs for over 300 iterations and for 3 hours"
      ],
      "metadata": {
        "id": "ao2QOzuCI76E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Summary**\n",
        "\n",
        "Tried various techniques. The best performance with test accuracy of 61% I got was via xgboost and SMOTE. Many other techniques seem to overfit on training data and thereby we need to do more with undersampling majority, oversampling minority to make model better.  "
      ],
      "metadata": {
        "id": "AKg8X2UrJSQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brian's Section"
      ],
      "metadata": {
        "id": "WwSMbbKAy-Ng"
      }
    }
  ]
}